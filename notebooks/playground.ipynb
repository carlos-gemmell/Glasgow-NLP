{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code playground\n",
    "This notebook is a small sandbox where half baked ideas can live. Code snippets that were developed but might be useful saterr can go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(1,2),(3,4)]\n",
    "b = [5,6]\n",
    "\n",
    "b .index (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split( \" *\" , \"foo bar baz\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'a':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def super_print(filename):\n",
    "    '''filename is the file where output will be written'''\n",
    "    def wrap(func):\n",
    "        '''func is the function you are \"overriding\", i.e. wrapping'''\n",
    "        def wrapped_func(*args,**kwargs):\n",
    "            '''*args and **kwargs are the arguments supplied \n",
    "            to the overridden function'''\n",
    "            #use with statement to open, write to, and close the file safely\n",
    "            with open(filename,'a') as outputfile:\n",
    "                now = datetime.now()\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                outputfile.write(\"[{}] \".format(dt_string))\n",
    "                outputfile.write(\" \".join(str(x) for x in args))\n",
    "                outputfile.write(\"\\n\")\n",
    "            #now original function executed with its arguments as normal\n",
    "            return func(*args,**kwargs)\n",
    "        return wrapped_func\n",
    "    return wrap\n",
    "\n",
    "print = super_print('logs-playground.txt')(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 2, 1, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,4,3,6,2]).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_transformer_model = nn.Transformer().to(\"cuda\") # uses default hyperparameters\n",
    "src = torch.rand((10, 32, 512)).to(\"cuda\") # [src_seq_length, batch_size, embedding_size]\n",
    "tgt = torch.rand((20, 32, 512)).to(\"cuda\") # [tgt_seq_length, batch_size, embedding_size]\n",
    "rand_transformer_model(src, tgt).shape # [tgt_seq_length, batch_size, embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c11c7d636f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import linecache\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "# import streamtologger\n",
    "# streamtologger.redirect(target=\"./logs-playground.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (multihead_attn): MultiheadAttention(\n",
       "    (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_transformer_model.decoder.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand((20, 32, 512))\n",
    "k = torch.rand((10, 32, 512))\n",
    "v = torch.rand((10, 32, 512))\n",
    "att = nn.MultiheadAttention(512, 2)\n",
    "attn_output = att(q, k, v)\n",
    "# attn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-made beam search code\n",
    "This code runs on paralelised batches and beams, it's fast, but doesn't have the appropriate stopping conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode_batch_ids(encoder_input, beam_size=3, max_seq_length=50):\n",
    "    batch_len = encoder_input.shape[1]\n",
    "    sos_id = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    decoder_input = torch.zeros((1, beam_size * batch_len), dtype=torch.long, device=device).fill_(sos_id)\n",
    "    log_probs = torch.zeros((beam_size * batch_len,1))\n",
    "    print(\"log_probs:\", log_probs)\n",
    "    vocab_size = len(TGT_TEXT.vocab.itos)\n",
    "    \n",
    "    encoder_input = encoder_input.view(-1,1).repeat(1,beam_size).view(-1,beam_size * batch_len) # this tiles the input to the beam size * batch size\n",
    "    print(\"tiled input:\", encoder_input)\n",
    "    \n",
    "    for i in range(max_seq_length):\n",
    "        output = model(encoder_input, decoder_input)\n",
    "        print(output.shape)\n",
    "        last_pred = output[-1].softmax(1)\n",
    "        print(\"last_pred shape:\", last_pred.shape)\n",
    "        log_predictions = last_pred.log()\n",
    "        seq_log_probs = log_predictions + log_probs.repeat(1,vocab_size)\n",
    "        print(\"seq_log_probs:\", seq_log_probs)\n",
    "        \n",
    "        seq_log_probs_positions = seq_log_probs.view(batch_len,-1).argsort(1)[:,-beam_size:]\n",
    "        print(\"seq_log_probs_positions:\", seq_log_probs_positions)\n",
    "        next_ids = seq_log_probs_positions.reshape(1, batch_len*beam_size) % vocab_size\n",
    "        print(\"next_ids:\", next_ids)\n",
    "        log_probs = seq_log_probs.view(batch_len,-1).gather(1,seq_log_probs_positions).view(beam_size * batch_len,1)\n",
    "        print(\"log_probs:\",log_probs)\n",
    "        \n",
    "        for batch_idx in range(seq_log_probs_positions.shape[0]):\n",
    "            for seq_choice_idx in range(seq_log_probs_positions.shape[1]):\n",
    "                seq_choice = seq_log_probs_positions[batch_idx,seq_choice_idx] // vocab_size\n",
    "                decoder_input[:,batch_idx*batch_len + seq_choice_idx] = decoder_input[:,batch_idx*batch_len + seq_choice]\n",
    "        \n",
    "        decoder_input = torch.cat((decoder_input, next_ids))\n",
    "    return decoder_input\n",
    "        \n",
    "#         last_pred = output[-1].argsort(dim=1)[:,:beam_size]\n",
    "\n",
    "sent1 = [\"<sos>\"] + SRC_TEXT.preprocess(\"create array\") + [\"<eos>\"] + [\"<pad>\"]\n",
    "sent2 = [\"<sos>\"] + SRC_TEXT.preprocess(\"if exists then\") + [\"<eos>\"]\n",
    "src_ids = SRC_TEXT.numericalize([sent1, sent2], device=device)\n",
    "print(\"input ids:\", src_ids)\n",
    "beam_search_decode_batch_ids(src_ids, max_seq_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non batch single node beam search\n",
    "This is the original beam search from online simply adapted to suit the transformerr architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return True\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        beta = 4.0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decode(model, encoder_states):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "\n",
    "    beam_width = 10\n",
    "    topk = 3  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "    \n",
    "    SOS_token = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    EOS_token = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "    MAX_LENGTH = 7\n",
    "    \n",
    "    batch_size = encoder_states.shape[1]\n",
    "\n",
    "    # decoding goes sentence by sentence\n",
    "    for idx in range(batch_size):\n",
    "        encoder_input = encoder_states[:, idx].view(-1,1)\n",
    "        \n",
    "        # Start with the start of the sentence token\n",
    "        decoder_input = torch.LongTensor([[SOS_token]]).to(device)\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_input, None, SOS_token, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "\n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 400: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "#             decoder_input = n.wordid\n",
    "            decoder_input = n.h\n",
    "\n",
    "            if n.wordid == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "#             print(encoder_input)\n",
    "#             print(decoder_input)\n",
    "            decoder_output = model(encoder_input, decoder_input)\n",
    "            last_token_logits = decoder_output[-1]\n",
    "            last_token_logs = last_token_logits.log_softmax(1)\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(last_token_logs, beam_width)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[0][new_k]\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "                decoder_input = torch.cat((decoder_input,decoded_t.view(1,-1)))\n",
    "                node = BeamSearchNode(decoder_input, n, decoded_t.cpu().item(), n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "\n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "        utterances = []\n",
    "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "            utterance = []\n",
    "            utterance.append(n.wordid)\n",
    "            # back trace\n",
    "            while n.prevNode != None:\n",
    "                n = n.prevNode\n",
    "                utterance.append(n.wordid)\n",
    "\n",
    "            utterance = utterance[::-1]\n",
    "            utterances.append(utterance)\n",
    "\n",
    "        decoded_batch.append(utterances)\n",
    "\n",
    "    return decoded_batch\n",
    "\n",
    "sent1 = [\"<sos>\"] + SRC_TEXT.preprocess(\"call the options.get method with string 'CULL_FREQUENCY' and integer 3 as arguments, use the string 'cull_frequency' and previous result as the arguments for the call to the params.get method, substitute the result for cull_frequency.\") + [\"<eos>\"] + [\"<pad>\"]\n",
    "# sent2 = [\"<sos>\"] + SRC_TEXT.preprocess(\"if not,\") + [\"<eos>\"]\n",
    "src_ids = SRC_TEXT.numericalize([sent1], device=device)\n",
    "# print(\"input ids:\", src_ids)\n",
    "outs = beam_decode(model, encoder_states=src_ids)\n",
    "\n",
    "for b in outs:\n",
    "    for sent in b:\n",
    "        print([TGT_TEXT.vocab.itos[id] for id in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation of node based beam search to parallelise batches\n",
    "This version comes from an already working version for a single batch. But there is a problem since when decodng different batches and passing them to the transformer, they all need to be the same length which doesn't work since there could be a node made in the past with a better probability score.\n",
    "It doesn't look too obvious from what I see to speed it up while rretaining the theoretical benefits of being able to explore the full tree of options.\n",
    "\n",
    "### The solution\n",
    "You just need to add padding to the decoded sequences that are shorter and keep track of the position that you need to take the output token from. easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRC_TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-86d3751bbcca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0msent1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSRC_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'try,'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0msent2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSRC_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"if not,\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0msrc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRC_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SRC_TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "def beam_decode(model, encoder_states):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "\n",
    "    beam_width = 10\n",
    "    topk = 3  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "    \n",
    "    batch_size = encoder_states.shape[1]\n",
    "    \n",
    "    SOS_token = TGT_TEXT.vocab.stoi[\"<sos>\"]\n",
    "    EOS_token = TGT_TEXT.vocab.stoi[\"<eos>\"]\n",
    "    MAX_LENGTH = 7\n",
    "\n",
    "    # decoding goes all batches at the same time\n",
    "    encoder_input = encoder_states\n",
    "\n",
    "    # Start with the start of the sentence token\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]).to(device)\n",
    "\n",
    "    # Number of sentence to generate\n",
    "    batch_endnodes = [[] for i in range(batch_size)]\n",
    "    number_required = topk\n",
    "\n",
    "    # starting node -  hidden vector, previous node, word id, logp, length\n",
    "    batch_node = [BeamSearchNode(decoder_input, None, SOS_token, 0, 1) for i in range(batch_size)]\n",
    "    batch_nodes = [PriorityQueue() for i in range(batch_size)]\n",
    "\n",
    "    # start the queue\n",
    "    for nodes, node in zip(batch_nodes, batch_node):\n",
    "        nodes.put((-node.eval(), node))\n",
    "        \n",
    "    batch_qsize = [1 for i in range(batch_size)]\n",
    "\n",
    "    # start beam search\n",
    "    while True:\n",
    "        # give up when decoding takes too long for the first batch, placeholder for now\n",
    "        print(batch_qsize)\n",
    "        if batch_qsize[0] > 200: break\n",
    "\n",
    "        # fetch the best node\n",
    "        best_nodes = [nodes.get() for nodes in batch_nodes]\n",
    "#         score, n = nodes.get()\n",
    "#             decoder_input = n.wordid\n",
    "#         decoder_input = n.h\n",
    "        \n",
    "        finished_nodes = [True if n.wordid == EOS_token and n.prevNode != None else False for (score, n) in best_nodes]\n",
    "        print(finished_nodes)\n",
    "        \n",
    "        working_nodes = []\n",
    "        working_node_id = 0\n",
    "        working_nodes_idx = []\n",
    "        for endnodes, (score, n) in zip(batch_endnodes, best_nodes):\n",
    "            if n.wordid == EOS_token and n.prevNode != None and len(endnodes) < number_required:\n",
    "                endnodes.append((score, n))\n",
    "            else:\n",
    "                working_nodes.append((score, n))\n",
    "                working_nodes_idx.append(working_node_id)\n",
    "            working_node_id += 1\n",
    "        \n",
    "        if all([len(endnodes) >= number_required for endnodes in batch_endnodes]):\n",
    "            break\n",
    "        \n",
    "        num_working_nodes = len(working_nodes)\n",
    "        print(working_nodes)\n",
    "        \n",
    "        step_encoder_input = encoder_input[:,:num_working_nodes].view(-1,num_working_nodes)\n",
    "        print(\"[n.h for (score, n) in working_nodes] shape:\", [n.h.shape for (score, n) in working_nodes])\n",
    "        step_decoder_input = torch.cat([n.h for (score, n) in working_nodes],dim=1)\n",
    "#         print(\"step_encoder_input shape:\", step_encoder_input.shape)\n",
    "        step_decoder_output = model(step_encoder_input, step_decoder_input)\n",
    "        step_token_logits = step_decoder_output[-1]\n",
    "        \n",
    "        print(step_token_logits)\n",
    "\n",
    "        # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "        log_prob, indexes = torch.topk(step_token_logits, beam_width)\n",
    "        print(log_prob.shape)\n",
    "        \n",
    "    \n",
    "        nextnodes = []\n",
    "        \n",
    "        for batch_id in working_nodes_idx:\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[batch_id][new_k]\n",
    "                log_p = log_prob[batch_id][new_k].item()\n",
    "#                 print(\"decoder_input shape\", step_decoder_input.shape)\n",
    "#                 print(\"step_decoder_input shape:\", step_decoder_input[:,batch_id].view(-1,1).shape)\n",
    "#                 print(\"decoded_t shape:\", decoded_t.view(1,-1).shape)\n",
    "                decoder_input = torch.cat((step_decoder_input[:,batch_id].view(-1,1),decoded_t.view(1,-1)), dim=0)\n",
    "#                 print(\"decoder_input shape:\", decoder_input.shape)\n",
    "                node = BeamSearchNode(decoder_input, working_nodes[batch_id], decoded_t.cpu().item(), n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                batch_nodes[batch_id].put((score, node))\n",
    "                batch_qsize[batch_id] += 1\n",
    "        \n",
    "        # put them into queue\n",
    "#         for i in range(len(nextnodes)):\n",
    "#             score, nn = nextnodes[i]\n",
    "#             nodes.put((score, nn))\n",
    "#             # increase qsize\n",
    "#         qsize += len(nextnodes) - 1\n",
    "\n",
    "    # choose nbest paths, back trace them\n",
    "    if len(endnodes) == 0:\n",
    "        endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "    utterances = []\n",
    "    for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "        utterance = []\n",
    "        utterance.append(n.wordid)\n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(n.wordid)\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "        utterances.append(utterance)\n",
    "\n",
    "    decoded_batch.append(utterances)\n",
    "\n",
    "    return decoded_batch\n",
    "\n",
    "sent1 = [\"<sos>\"] + SRC_TEXT.preprocess('try,') + [\"<eos>\"] + [\"<pad>\"]\n",
    "sent2 = [\"<sos>\"] + SRC_TEXT.preprocess(\"if not,\") + [\"<eos>\"]\n",
    "src_ids = SRC_TEXT.numericalize([sent1, sent2], device=device)\n",
    "# print(\"input ids:\", src_ids)\n",
    "[len(x) for x in beam_decode(model, encoder_states=src_ids)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_data = [\n",
    "#     (\"my favourite foods are banana and toast\",\"would you like banana and toast ?\"),\n",
    "#     (\"my favourite foods are eggs and bacon and beans\",\"would you like eggs and bacon and beans ?\"),\n",
    "#     (\"my favourite food is chocolate\",\"would you like chocolate ?\"),\n",
    "#     (\"my favourite food is avocado\",\"would you like avocado ?\")\n",
    "# ]\n",
    "\n",
    "# other_data = [\n",
    "#     (\"what age is she ?\", \"she is 8 years old\"),\n",
    "#     (\"what age is he ?\", \"he is 4 years old\"),\n",
    "#     (\"how old are you ?\", \"i am 22 years old\"),\n",
    "#     (\"how old am i ?\", \"you are 28 years old\")\n",
    "# ]\n",
    "\n",
    "# SRC_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "# TGT_TEXT = Field(sequential=True, tokenize=string_split, init_token='<sos>',eos_token='<eos>')\n",
    "\n",
    "# train_dataset = val_dataset = samples_to_dataset(other_data, SRC_TEXT, TGT_TEXT)\n",
    "\n",
    "# # train_dataset, val_dataset = dataset.split([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise to the decoding process during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf, 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, 0., 0., -inf, -inf, 0., -inf, -inf, -inf, -inf],\n",
       "        [0., -inf, 0., 0., -inf, -inf, 0., -inf, -inf, -inf],\n",
       "        [-inf, 0., 0., -inf, 0., 0., 0., 0., -inf, -inf],\n",
       "        [-inf, 0., 0., 0., 0., -inf, 0., -inf, 0., -inf],\n",
       "        [0., -inf, 0., 0., -inf, 0., -inf, 0., -inf, -inf]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_e = 0.4\n",
    "noise_mask = (torch.rand(10,10) > noise_e).float()\n",
    "\n",
    "mask = (torch.triu(torch.ones(10,10))).transpose(0, 1)\n",
    "mask = torch.mul(mask, noise_mask)\n",
    "v = (torch.sum(mask, dim=-1) == 0).float()\n",
    "\n",
    "fix_mask = torch.zeros(10,10)\n",
    "fix_mask[:,0] = 1.0\n",
    "v = v.repeat(10, 1).transpose(0,1)\n",
    "fix_mask = torch.mul(fix_mask,v)\n",
    "\n",
    "print(fix_mask)\n",
    "mask += fix_mask\n",
    "\n",
    "\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch target masking transformer bug\n",
    "There is a bug in the implementation of the transformer attention mask during decoding. It being produced the other way round, paying attention to parts of the sentence that appear at the end. It is a simple to fix at removing ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Transformer()\n",
    "model.generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 4\n",
    "mask = (torch.triu(torch.ones(sz, sz))==1).transpose(0, 1).float()\n",
    "print(mask)\n",
    "mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.ones(10)==1)\n",
    "a.masked_fill(a == 1, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from queue import PriorityQueue\n",
    "a = PriorityQueue()\n",
    "a.put(torch.tensor(1))\n",
    "a.put(torch.tensor(-2))\n",
    "a.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[1., 3.],\n",
      "        [2., 4.],\n",
      "        [3., 7.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1],[2],[3]])\n",
    "b = torch.tensor([[3],[4]])\n",
    "rough_input = [a,b]\n",
    "m = max([t.shape[0] for t in rough_input])\n",
    "print(m)\n",
    "z = torch.zeros((m,2)).fill_(7)\n",
    "for i in range(2):\n",
    "    length = rough_input[i].shape[0]\n",
    "    z[:length,i] = rough_input[i].view(-1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8]])\n"
     ]
    }
   ],
   "source": [
    "outputs = torch.tensor([[[1],[5]],[[2],[6]],[[3],[7]],[[4],[8]]]).transpose(0,1)\n",
    "p_mask = [2,3]\n",
    "\n",
    "for l in outputs[]:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0259, 0.0705, 0.1917, 0.5210, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095,\n",
       "        0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095,\n",
       "        0.0095, 0.0095, 0.0095, 0.0095, 0.0095, 0.0095])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.,2,3,4, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]).softmax(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atts: tensor([[[0.0248, 0.1017, 0.7406],\n",
      "         [0.8730, 0.7230, 0.6886]],\n",
      "\n",
      "        [[0.0148, 0.6740, 0.0523],\n",
      "         [0.4018, 0.8585, 0.9774]],\n",
      "\n",
      "        [[0.9876, 0.9629, 0.4758],\n",
      "         [0.0139, 0.4103, 0.1767]],\n",
      "\n",
      "        [[0.9024, 0.3109, 0.5361],\n",
      "         [0.5023, 0.6643, 0.6590]]])\n",
      "atts.shape: torch.Size([4, 2, 3])\n",
      "atts: tensor([[[0.0248, 0.1017, 0.7406],\n",
      "         [0.8730, 0.7230, 0.6886]],\n",
      "\n",
      "        [[0.0148, 0.6740, 0.0523],\n",
      "         [0.4018, 0.8585, 0.9774]],\n",
      "\n",
      "        [[0.9876, 0.9629, 0.4758],\n",
      "         [0.0139, 0.4103, 0.1767]],\n",
      "\n",
      "        [[0.9024, 0.3109, 0.5361],\n",
      "         [0.5023, 0.6643, 0.6590]]])\n",
      "src: tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "src.T: tensor([[1, 3, 5],\n",
      "        [2, 4, 6]])\n",
      "src.unsqueeze: tensor([[[1, 3, 5],\n",
      "         [2, 4, 6]]])\n",
      "src.inter: tensor([[[1, 3, 5],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 5],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 5],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 5],\n",
      "         [2, 4, 6]]])\n",
      "src.inter.shape: torch.Size([4, 2, 3])\n",
      "tensor([[[0.0000, 0.0248, 0.0000, 0.1017, 0.0000, 0.7406, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.8730, 0.0000, 0.7230, 0.0000, 0.6886, 0.0000,\n",
      "          0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0148, 0.0000, 0.6740, 0.0000, 0.0523, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.4018, 0.0000, 0.8585, 0.0000, 0.9774, 0.0000,\n",
      "          0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.9876, 0.0000, 0.9629, 0.0000, 0.4758, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0139, 0.0000, 0.4103, 0.0000, 0.1767, 0.0000,\n",
      "          0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.9024, 0.0000, 0.3109, 0.0000, 0.5361, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.5023, 0.0000, 0.6643, 0.0000, 0.6590, 0.0000,\n",
      "          0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "atts = torch.rand(2,4,3).transpose(0,1) # [output_seq_length, batch_size, input_seq_length]\n",
    "print(\"atts:\", atts)\n",
    "print(\"atts.shape:\", atts.shape)\n",
    "\n",
    "# atts = atts * torch.tensor([[[0.1],[1]],[[10],[100]],[[1000],[10000]],[[100000],[1000000]]])\n",
    "print(\"atts:\", atts)\n",
    "\n",
    "# src = torch.randint(0, 10, (3,2))\n",
    "src = torch.tensor([[1,2],\n",
    "                    [3,4],\n",
    "                    [5,6]])\n",
    "print(\"src:\", src)\n",
    "src = src.transpose(0,1)\n",
    "print(\"src.T:\", src)\n",
    "src = src.unsqueeze(0)\n",
    "print(\"src.unsqueeze:\", src)\n",
    "src = torch.repeat_interleave(src, 4, dim=0)\n",
    "print(\"src.inter:\", src)\n",
    "print(\"src.inter.shape:\", src.shape)\n",
    "\n",
    "out_dist = torch.zeros(4, 2, 10).scatter_add_(2,src,atts)\n",
    "print(out_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python AST doodles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astor\n",
    "\n",
    "import execnet\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_python_version(Version, Module, Function, ArgumentList):\n",
    "    gw      = execnet.makegateway(\"popen//python=python%s\" % Version)\n",
    "    channel = gw.remote_exec(\"\"\"\n",
    "        from %s import %s as the_function\n",
    "        channel.send(the_function(*channel.receive()))\n",
    "    \"\"\" % (Module, Function))\n",
    "    channel.send(ArgumentList)\n",
    "    return channel.receive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(*bar):\n",
    "    print(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def foo(*bar):\n",
      "    print(bar)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func_source = inspect.getsource(foo)\n",
    "print(func_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this', 'is')\n"
     ]
    }
   ],
   "source": [
    "foo(\"this\", \"is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_as_python2(code_string):\n",
    "    gw = execnet.makegateway(\"popen//python=python2\")\n",
    "    channel = gw.remote_exec(f\"\"\"\n",
    "        channel.send(\"the_function(*channel.receive())\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mr Bear!\n"
     ]
    },
    {
     "ename": "RemoteError",
     "evalue": "Traceback (most recent call last):\n  File \"<string>\", line 1084, in executetask\n  File \"<string>\", line 1, in do_exec\n  File \"<remote exec>\", line 3, in <module>\n  File \"<string>\", line 729, in send\n  File \"<string>\", line 1371, in dumps_internal\n  File \"<string>\", line 1389, in save\n  File \"<string>\", line 1405, in _save\nDumpError: can't serialize <class '_ast.Module'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-aa1903dbbfd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m result = call_python_version(\"2\", \"python2_code\", \"string_py2_ast\",  \n\u001b[0;32m----> 5\u001b[0;31m                              [\"print 'foo' \"]) \n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7d10cd00bb25>\u001b[0m in \u001b[0;36mcall_python_version\u001b[0;34m(Version, Module, Function, ArgumentList)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\" % (Module, Function))\n\u001b[1;32m      7\u001b[0m     \u001b[0mchannel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArgumentList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/execnet/gateway_base.py\u001b[0m in \u001b[0;36mreceive\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mENDMARKER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mitemqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for other receivers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getremoteerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRemoteError\u001b[0m: Traceback (most recent call last):\n  File \"<string>\", line 1084, in executetask\n  File \"<string>\", line 1, in do_exec\n  File \"<remote exec>\", line 3, in <module>\n  File \"<string>\", line 729, in send\n  File \"<string>\", line 1371, in dumps_internal\n  File \"<string>\", line 1389, in save\n  File \"<string>\", line 1405, in _save\nDumpError: can't serialize <class '_ast.Module'>\n"
     ]
    }
   ],
   "source": [
    "result = call_python_version(\"3\", \"python2_code\", \"my_function\",  \n",
    "                             [\"Mr\", \"Bear\"]) \n",
    "print(result) \n",
    "result = call_python_version(\"2\", \"python2_code\", \"string_py2_ast\",  \n",
    "                             [\"print 'foo' \"]) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_ast.Store"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "def is_primitive(obj):\n",
    "    return any([isinstance(obj, str),isinstance(obj, int),isinstance(obj, float)])\n",
    "\n",
    "def ast_to_production_rules(tree):\n",
    "    \n",
    "    fields = tree._fields\n",
    "    name = type(tree).__name__\n",
    "    print(name, end =\" \")\n",
    "    \n",
    "    for field in fields:\n",
    "        field_obj = getattr(tree, field)\n",
    "        \n",
    "        if field_obj==None:\n",
    "            continue\n",
    "            \n",
    "        elif is_primitive(field_obj):\n",
    "            print(field, end=\" \")\n",
    "            print(field_obj, end=\" \")\n",
    "            \n",
    "        elif isinstance(field_obj, Iterable):\n",
    "            print(field, end=\" \")\n",
    "            for elem in field_obj:\n",
    "                ast_to_production_rules(elem)\n",
    "            print(\"<end_list>\", end=\" \")\n",
    "        else:\n",
    "            print(field, end=\" \")\n",
    "            ast_to_production_rules(field_obj)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module body Assign targets Name id a ctx Store <end_list> value Num n 0.4 <end_list> "
     ]
    }
   ],
   "source": [
    "ast_to_production_rules(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this ' is\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='this \\' is'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Expr(value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]))])\n",
      "\n",
      "parser.add_argument('app_label', help=\n",
      "    'App label of the application containing the migration.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_string = \"parser . add_argument ( 'app_label' ,  help = 'App label of the application containing the migration.' )\"\n",
    "tree = ast.parse(code_string)\n",
    "# tree = ast.parse(\"a='foo'\")\n",
    "print(ast.dump(tree))\n",
    "print()\n",
    "print(astor.to_source(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return float(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Expr(value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]))])\n",
      "\n",
      "Reduced tree: Module(body=[Expr(value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]))])\n",
      "2 Attr string so far: body=[Expr(value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]))]\n",
      "3 attribute name: body\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))])\n",
      "3 attribute name: value\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]\n",
      "3 attribute name: func\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()\n",
      "3 attribute name: value\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: id='parser', ctx=Load()\n",
      "3 attribute name: id\n",
      "6 checking Quote or DQuote: True\n",
      "2 Attr string so far: ctx=Load()\n",
      "3 attribute name: ctx\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: attr='add_argument', ctx=Load()\n",
      "3 attribute name: attr\n",
      "6 checking Quote or DQuote: True\n",
      "2 Attr string so far: ctx=Load()\n",
      "3 attribute name: ctx\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]\n",
      "3 attribute name: args\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: s='app_label'\n",
      "3 attribute name: s\n",
      "6 checking Quote or DQuote: True\n",
      "2 Attr string so far: keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]\n",
      "3 attribute name: keywords\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: arg='help', value=Str(s='App label of the application containing the migration.')\n",
      "3 attribute name: arg\n",
      "6 checking Quote or DQuote: True\n",
      "2 Attr string so far: value=Str(s='App label of the application containing the migration.')\n",
      "3 attribute name: value\n",
      "6 checking Quote or DQuote: False\n",
      "2 Attr string so far: s='App label of the application containing the migration.'\n",
      "3 attribute name: s\n",
      "6 checking Quote or DQuote: True\n",
      "\n",
      "Module(body=[Expr(value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument', ctx=Load()), args=[Str(s='app_label')], keywords=[keyword(arg='help', value=Str(s='App label of the application containing the migration.'))]))])\n",
      "\n",
      "OG String    : parser . add_argument ( 'app_label' ,  help = 'App label of the application containing the migration.' )\n",
      "Code from AST: parser.add_argument('app_label', help=\n",
      "    'App label of the application containing the migration.')\n",
      "\n",
      "Rebuilt AST  : parser.add_argument('app_label', help=\n",
      "    'App label of the application containing the migration.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "def new_dump_to_ast(dump_string):\n",
    "    first_paren = dump_string.index(\"(\")\n",
    "    node_string = dump_string[:first_paren]\n",
    "#     print(1, \"creating node type:\", node_string)\n",
    "    module = importlib.import_module(\"ast\")\n",
    "    class_ = getattr(module, node_string)\n",
    "    node = class_()\n",
    "    inner_paren = dump_string[first_paren+1:-1]\n",
    "    \n",
    "    # handle variable length attributes\n",
    "    while len(inner_paren) > 0:\n",
    "        print(2, \"Attr string so far:\", inner_paren)\n",
    "        equal_idx = inner_paren.index(\"=\")\n",
    "        attr_string = inner_paren[:equal_idx]\n",
    "        print(3, \"attribute name:\", attr_string)\n",
    "        \n",
    "        # 5 cases: None, num, string, list, node\n",
    "        # first check if None\n",
    "#         print(4, \"checking None:\", inner_paren[equal_idx+1:equal_idx+5])\n",
    "#         print(5, \"checking number:\", inner_paren[equal_idx+1], inner_paren[equal_idx+1].isnumeric())\n",
    "        print(6, \"checking Quote or DQuote:\", inner_paren[equal_idx+1] == \"'\" or inner_paren[equal_idx+1] == '\"')\n",
    "        \n",
    "        if inner_paren[equal_idx+1:equal_idx+5] == \"None\":\n",
    "            setattr(node, attr_string, None)\n",
    "            inner_paren = inner_paren[equal_idx + 7:]\n",
    "        \n",
    "        elif inner_paren[equal_idx+1:equal_idx+5] == \"True\":\n",
    "            setattr(node, attr_string, True)\n",
    "            inner_paren = inner_paren[equal_idx + 7:]\n",
    "            \n",
    "        elif inner_paren[equal_idx+1:equal_idx+6] == \"False\":\n",
    "            setattr(node, attr_string, False)\n",
    "            inner_paren = inner_paren[equal_idx + 8:]\n",
    "            \n",
    "        # check if first character is a number\n",
    "        elif inner_paren[equal_idx+1].isnumeric():\n",
    "            number_finder = re.compile(\"([0-9]+(.?[0-9]*))( *([a-zA-Z]+))*\")\n",
    "            groups = number_finder.match(inner_paren[equal_idx+1:]).groups()\n",
    "#             print(6, \"Number groups identified:\", groups)\n",
    "            num = to_num(groups[0])\n",
    "#             print(7, \"Number:\", num)\n",
    "            setattr(node, attr_string, num)\n",
    "            inner_paren = inner_paren[equal_idx + len(groups[0])+2:]\n",
    "        \n",
    "        # check if first Character is quote or double quote to see if it's a string\n",
    "        elif inner_paren[equal_idx+1] == \"'\" or inner_paren[equal_idx+1] == '\"':\n",
    "            string_matcher = re.compile(\"['\\\"](.*?)['\\\"]\")\n",
    "            string = string_matcher.findall(inner_paren[equal_idx:])[0]\n",
    "            setattr(node, attr_string, string)\n",
    "            inner_paren = inner_paren[equal_idx + len(string)+5:]\n",
    "        \n",
    "        # deal with list\n",
    "        elif inner_paren[equal_idx+1] == \"[\":\n",
    "            list_last_square = get_square_index(inner_paren, equal_idx+1)\n",
    "            list_string = inner_paren[equal_idx+2:list_last_square]\n",
    "            \n",
    "            elem_list = []\n",
    "            while len(list_string) > 0:\n",
    "#                 print(8, \"List string so far:\", list_string)\n",
    "                value_first_paren = list_string.index(\"(\")\n",
    "                value_last_paren = get_paren_index(list_string, value_first_paren)\n",
    "                list_value_ast = new_dump_to_ast(list_string[:value_last_paren+1])\n",
    "                elem_list.append(list_value_ast)\n",
    "                list_string = list_string[value_last_paren+3:]\n",
    "            setattr(node, attr_string, elem_list)\n",
    "            inner_paren = inner_paren[list_last_square+3:]\n",
    "        \n",
    "        # deal with node\n",
    "        else:\n",
    "            value_first_paren = inner_paren.index(\"(\")        \n",
    "            value_last_paren = get_paren_index(inner_paren, value_first_paren)\n",
    "#             print(9,\"handling Node for: \",inner_paren[equal_idx+1:value_last_paren+1])\n",
    "            value_ast = new_dump_to_ast(inner_paren[equal_idx+1:value_last_paren+1])\n",
    "#             print(10, f\"obtained AST for{attr_string}:\", value_ast)\n",
    "            setattr(node, attr_string, value_ast)\n",
    "            inner_paren = inner_paren[value_last_paren+3:]\n",
    "    \n",
    "    \n",
    "    return node\n",
    "\n",
    "print(ast.dump(tree))\n",
    "print()\n",
    "t = tree\n",
    "print(\"Reduced tree:\", ast.dump(t))\n",
    "new_ast = new_dump_to_ast(ast.dump(t))\n",
    "\n",
    "print()\n",
    "print(ast.dump(new_ast))\n",
    "\n",
    "print()\n",
    "print(f\"OG String    : {code_string}\")\n",
    "print(f\"Code from AST: {astor.to_source(t)}\")\n",
    "print(f\"Rebuilt AST  : {astor.to_source(new_ast)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_ast.Module"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "module = importlib.import_module(\"ast\")\n",
    "class_ = getattr(module, \"Module\")\n",
    "instance = class_()\n",
    "type(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/all.code\", \"r\") as f:\n",
    "    count = 0\n",
    "    all_lines = 0\n",
    "    for line in f.readlines():\n",
    "        all_lines+=1\n",
    "        try:\n",
    "            can_code = canonicalize_code(line[:-1])\n",
    "            code_ast = ast.parse(can_code)\n",
    "            new_ast = new_dump_to_ast(ast.dump(code_ast))\n",
    "            can_code_ast = astor.to_source(new_ast)\n",
    "\n",
    "            de_can_code_ast = de_canonicalize_code(can_code_ast, code)\n",
    "            de_can_code_ast = re.sub(r'\\n', '', de_can_code_ast)\n",
    "            count += 1\n",
    "        except:\n",
    "            print(line[:-1])\n",
    "            pass\n",
    "print(f\"{count}/{all_lines} = {count*100/all_lines:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  else :\n",
      "if True: pass\n",
      "else :pass\n",
      "2 Attr string so far: body=[If(test=NameConstant(value=True), body=[Pass()], orelse=[Pass()])]\n",
      "3 attribute name: body\n",
      "6 checking Quote or DQuote: False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_square_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f25fc97a4842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcan_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mcode_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcan_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mnew_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_dump_to_ast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_ast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mcan_code_ast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcan_code_ast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a195fd12c322>\u001b[0m in \u001b[0;36mnew_dump_to_ast\u001b[0;34m(dump_string)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# deal with list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minner_paren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mequal_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"[\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mlist_last_square\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_square_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_paren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mlist_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_paren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mequal_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist_last_square\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_square_index' is not defined"
     ]
    }
   ],
   "source": [
    "p_elif = re.compile(r'^elif\\s?')\n",
    "p_else = re.compile(r'^else\\s?')\n",
    "p_try = re.compile(r'^try\\s?')\n",
    "p_except = re.compile(r'^except\\s?')\n",
    "p_finally = re.compile(r'^finally\\s?')\n",
    "p_decorator = re.compile(r'^@.*')\n",
    "\n",
    "\n",
    "def canonicalize_code(code):\n",
    "    code = code.strip()\n",
    "    if p_elif.match(code):\n",
    "        code = 'if True: pass\\n' + code\n",
    "\n",
    "    if p_else.match(code):\n",
    "        code = 'if True: pass\\n' + code\n",
    "\n",
    "    if p_try.match(code):\n",
    "        code = code + 'pass\\nexcept: pass'\n",
    "    elif p_except.match(code):\n",
    "        code = 'try: pass\\n' + code\n",
    "    elif p_finally.match(code):\n",
    "        code = 'try: pass\\n' + code\n",
    "\n",
    "    if p_decorator.match(code):\n",
    "        code = code + '\\ndef dummy(): pass'\n",
    "\n",
    "    if code[-1] == ':':\n",
    "        code = code + 'pass'\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "def de_canonicalize_code(code, ref_raw_code):\n",
    "    ref_raw_code = ref_raw_code.strip()\n",
    "    if code.endswith('def dummy():\\n    pass'):\n",
    "        code = code.replace('def dummy():\\n    pass', '').strip()\n",
    "\n",
    "    if p_elif.match(ref_raw_code):\n",
    "        # remove leading if true\n",
    "        code = code.replace('if True:\\n    pass', '').strip()\n",
    "    elif p_else.match(ref_raw_code):\n",
    "        # remove leading if true\n",
    "        code = code.replace('if True:\\n    pass', '').strip()\n",
    "\n",
    "    # try/catch/except stuff\n",
    "    if p_try.match(ref_raw_code):\n",
    "        code = code.replace('except:\\n    pass', '').strip()\n",
    "    elif p_except.match(ref_raw_code):\n",
    "        code = code.replace('try:\\n    pass', '').strip()\n",
    "    elif p_finally.match(ref_raw_code):\n",
    "        code = code.replace('try:\\n    pass', '').strip()\n",
    "\n",
    "    # remove ending pass\n",
    "    if code.endswith(':\\n    pass\\n') or code.endswith(':\\n    pass'):\n",
    "        code = code.replace('\\n    pass', '').strip()\n",
    "\n",
    "    return code\n",
    "\n",
    "code = linecache.getline(\"datasets/all.code\", 18345).rstrip()\n",
    "print(code)\n",
    "# code = \"eol_message = message . replace ( str ( '\\r\\n' ) , str ( '\\n' ) ) . replace ( str ( '\\r' ) , str ( '\\n' ) )\"\n",
    "can_code = canonicalize_code(code)\n",
    "print(can_code)\n",
    "code_ast = ast.parse(can_code)\n",
    "new_ast = new_dump_to_ast(ast.dump(code_ast))\n",
    "can_code_ast = astor.to_source(new_ast)\n",
    "print(can_code_ast)\n",
    "de_can_code_ast = de_canonicalize_code(can_code_ast, code)\n",
    "print(de_can_code_ast)\n",
    "de_can_code_ast = re.sub(r'\\n', '', de_can_code_ast)\n",
    "print(de_can_code_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_square_index(\"[()th[]is]\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eol_message = message.replace(str('\\r\\n'), str('\\n')).replace(str('\\r'),    str('\\n'))\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r'\\n', '', can_code_ast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.3', '.3', None, None)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = re.compile(\"([0-9]+(.?[0-9]*))( *([a-zA-Z]+))*\") \n",
    "temp.match(\"3.3.dfd0\").groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a \" test\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-92bfb45f39d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"(?:\\\\\"|.)*?\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this is a \\\" test\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"='parser', ctx=Load()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "temp = re.compile('\"(?:\\\\\"|.)*?\"')\n",
    "print('this is a \\\" test\"')\n",
    "print(temp.findall(\"='parser', ctx=Load()\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'firstof statement requires at least one argument'"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_matcher = re.compile(\"['\\\"](.*?)['\\\"]\")\n",
    "string = string_matcher.findall('\"firstof statement requires at least one argument\" foo bar')[0]\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'foo'"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"foo\"\n",
    "a.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ABC[23]][89], 0: 8\n",
      "[ABC[23]][89], 4: 7\n",
      "[ABC[23]][89], 9: 12\n",
      "[ABC[23]][89], 1: -1\n"
     ]
    }
   ],
   "source": [
    "from collections import deque \n",
    "  \n",
    "def get_square_index(s, i): \n",
    "    if s[i] != '[': \n",
    "        return -1\n",
    "  \n",
    "    d = deque() \n",
    "    for k in range(i, len(s)): \n",
    "        if s[k] == ']': \n",
    "            d.popleft() \n",
    "\n",
    "        elif s[k] == '[': \n",
    "            d.append(s[i]) \n",
    "\n",
    "        if not d: \n",
    "            return k \n",
    "    return -1\n",
    "\n",
    "def get_paren_index(s, i): \n",
    "    if s[i] != '(': \n",
    "        return -1\n",
    "  \n",
    "    d = deque() \n",
    "    for k in range(i, len(s)): \n",
    "        if s[k] == ')': \n",
    "            d.popleft() \n",
    "\n",
    "        elif s[k] == '(': \n",
    "            d.append(s[i]) \n",
    "\n",
    "        if not d: \n",
    "            return k \n",
    "    return -1\n",
    "  \n",
    "# Driver code to test above method. \n",
    "def test(s, i): \n",
    "    matching_index = get_square_index(s, i) \n",
    "    print(s + \", \" + str(i) + \": \" + str(matching_index)) \n",
    "  \n",
    "def main(): \n",
    "    test(\"[ABC[23]][89]\", 0) # should be 8 \n",
    "    test(\"[ABC[23]][89]\", 4) # should be 7 \n",
    "    test(\"[ABC[23]][89]\", 9) # should be 12 \n",
    "    test(\"[ABC[23]][89]\", 1) # No matching bracket \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_as_python2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.body[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: astor.codetoast is deprecated.  Please use astor.code_to_ast.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '__code__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-77ae3589b921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mastor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodetoast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"print('foo')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/astor/__init__.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwarg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mnewfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0mModProxy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/astor/file_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, codeobj)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodeobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodeobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/astor/file_util.py\u001b[0m in \u001b[0;36mget_file_info\u001b[0;34m(codeobj)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlinenum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mfunc_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodeobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlinenum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_firstlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '__code__'"
     ]
    }
   ],
   "source": [
    "astor.codetoast(\"print('foo')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy_gen_transformer import Transformer\n",
    "model = Transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Assign (targets (list (Name (id (str val)) (ctx (Store -Store-))))) (value (Call (func (Attribute (value (Call (func (Name (id (str Header)) (ctx (Load -Load-)))) (args (list (Name (id (str val)) (ctx (Load -Load-))) (Name (id (str encoding)) (ctx (Load -Load-))))))) (attr (str encode)) (ctx (Load -Load-)))))))\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import sys\n",
    "import re\n",
    "import inspect\n",
    "\n",
    "def typename(x):\n",
    "    return type(x).__name__\n",
    "\n",
    "def escape(text):\n",
    "    text = text \\\n",
    "        .replace('\"', '`') \\\n",
    "        .replace('\\'', '`') \\\n",
    "        .replace(' ', '-SP-') \\\n",
    "        .replace('\\t', '-TAB-') \\\n",
    "        .replace('\\n', '-NL-') \\\n",
    "        .replace('(', '-LRB-') \\\n",
    "        .replace(')', '-RRB-') \\\n",
    "        .replace('|', '-BAR-')\n",
    "    return repr(text)[1:-1] if text else '-NONE-'\n",
    "\n",
    "def makestr(node):\n",
    "\n",
    "    #if node is None or isinstance(node, ast.Pass):\n",
    "    #    return ''\n",
    "\n",
    "    if isinstance(node, ast.AST):\n",
    "        n = 0\n",
    "        nodename = typename(node)\n",
    "        s = '(' + nodename\n",
    "        for chname, chval in ast.iter_fields(node):\n",
    "            chstr = makestr(chval)\n",
    "            if chstr:\n",
    "                s += ' (' + chname + ' ' + chstr + ')'\n",
    "                n += 1\n",
    "        if not n:\n",
    "            s += ' -' + nodename + '-' # (Foo) -> (Foo -Foo-)\n",
    "        s += ')'\n",
    "        return s\n",
    "\n",
    "    elif isinstance(node, list):\n",
    "        n = 0\n",
    "        s = '(list'\n",
    "        for ch in node:\n",
    "            chstr = makestr(ch)\n",
    "            if chstr:\n",
    "                s += ' ' + chstr\n",
    "                n += 1\n",
    "        s += ')'\n",
    "        return s if n else ''\n",
    "\n",
    "    elif isinstance(node, str):\n",
    "        return '(str ' + escape(node) + ')'\n",
    "\n",
    "    elif isinstance(node, bytes):\n",
    "        return '(bytes ' + escape(str(node)) + ')'\n",
    "\n",
    "    else:\n",
    "        return '(' + typename(node) + ' ' + str(node) + ')'\n",
    "\n",
    "\n",
    "def main():\n",
    "    p_elif = re.compile(r'^elif\\s?')\n",
    "    p_else = re.compile(r'^else\\s?')\n",
    "    p_try = re.compile(r'^try\\s?')\n",
    "    p_except = re.compile(r'^except\\s?')\n",
    "    p_finally = re.compile(r'^finally\\s?')\n",
    "    p_decorator = re.compile(r'^@.*')\n",
    "\n",
    "    for l in [\"\"\"val = Header ( val , encoding ) . encode ( )\"\"\"]:  # val = ', ' . join ( sanitize_address ( addr , encoding )  for addr in getaddresses ( ( val , ) ) )\n",
    "        l = l.strip()\n",
    "        if not l:\n",
    "            print()\n",
    "            sys.stdout.flush()\n",
    "            continue\n",
    "\n",
    "        if p_elif.match(l): l = 'if True: pass\\n' + l\n",
    "        if p_else.match(l): l = 'if True: pass\\n' + l\n",
    "\n",
    "        if p_try.match(l): l = l + 'pass\\nexcept: pass'\n",
    "        elif p_except.match(l): l = 'try: pass\\n' + l\n",
    "        elif p_finally.match(l): l = 'try: pass\\n' + l\n",
    "\n",
    "        if p_decorator.match(l): l = l + '\\ndef dummy(): pass'\n",
    "        if l[-1] == ':': l = l + 'pass'\n",
    "\n",
    "        parse = ast.parse(l)\n",
    "        parse = parse.body[0]\n",
    "        dump = makestr(parse)\n",
    "        print(dump)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch saving and restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.container import ModuleList\n",
    "import copy\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers=3, embedding_size=4):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers_foo = _get_clones(nn.Linear(embedding_size,embedding_size), num_layers)\n",
    "        self.activation_fn = nn.ReLU()\n",
    "            \n",
    "    def forward(self, inp):\n",
    "        output = inp\n",
    "        for i in range(self.num_layers):\n",
    "            output = self.layers_foo[i](output)\n",
    "            print(output.shape)\n",
    "            output = self.activation_fn(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "torch.Size([5, 4])\n",
      "torch.Size([5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2231, 0.0000, 0.4172, 0.0000],\n",
       "        [0.2352, 0.0000, 0.4164, 0.0000],\n",
       "        [0.2311, 0.0000, 0.4159, 0.0000],\n",
       "        [0.2271, 0.0000, 0.4177, 0.0000],\n",
       "        [0.2278, 0.0000, 0.4178, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_inp = torch.rand((5,4))\n",
    "\n",
    "simple_model = SimpleModel()\n",
    "simple_model(ex_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers_foo.0.weight',\n",
       "              tensor([[-0.2663,  0.1339, -0.2985, -0.3879],\n",
       "                      [-0.0576, -0.4047,  0.1100,  0.3523],\n",
       "                      [ 0.0260, -0.1466,  0.1175,  0.0271],\n",
       "                      [-0.1310, -0.1201,  0.2210, -0.4280]])),\n",
       "             ('layers_foo.0.bias',\n",
       "              tensor([ 0.4291, -0.2156,  0.3614, -0.4289])),\n",
       "             ('layers_foo.1.weight',\n",
       "              tensor([[-0.2663,  0.1339, -0.2985, -0.3879],\n",
       "                      [-0.0576, -0.4047,  0.1100,  0.3523],\n",
       "                      [ 0.0260, -0.1466,  0.1175,  0.0271],\n",
       "                      [-0.1310, -0.1201,  0.2210, -0.4280]])),\n",
       "             ('layers_foo.1.bias',\n",
       "              tensor([ 0.4291, -0.2156,  0.3614, -0.4289])),\n",
       "             ('layers_foo.2.weight',\n",
       "              tensor([[-0.2663,  0.1339, -0.2985, -0.3879],\n",
       "                      [-0.0576, -0.4047,  0.1100,  0.3523],\n",
       "                      [ 0.0260, -0.1466,  0.1175,  0.0271],\n",
       "                      [-0.1310, -0.1201,  0.2210, -0.4280]])),\n",
       "             ('layers_foo.2.bias',\n",
       "              tensor([ 0.4291, -0.2156,  0.3614, -0.4289]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_saved_state = simple_model.state_dict()\n",
    "simple_model_saved_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers=3, embedding_size=4):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers_foo = _get_clones(nn.Linear(embedding_size,embedding_size), num_layers)\n",
    "        self.activation_fn = nn.ReLU()\n",
    "            \n",
    "    def forward(self, inp):\n",
    "        output = inp\n",
    "        for i in range(self.num_layers):\n",
    "            output = self.layers_foo[i](output)\n",
    "            print(output.shape)\n",
    "            output = self.activation_fn(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte-pair encoding and tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train(files=[\"code_corpus_train.txt\"], vocab_size=32_000, min_frequency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./code_bpe_hugging_32k-vocab.json', './code_bpe_hugging_32k-merges.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save(\".\", \"code_bpe_hugging_32k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\"code_bpe_hugging_32k-vocab.json\",\"code_bpe_hugging_32k-merges.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids:  [1682, 396, 9904, 8241, 7208]\n",
      "token ids:  ['print', \"('\", 'hello', 'world', \"!')\"]\n"
     ]
    }
   ],
   "source": [
    "sent = \"print('hello world!')\"\n",
    "ids = tokenizer.encode(sent).ids\n",
    "print(\"token ids: \",ids)\n",
    "print(\"token ids: \",tokenizer.encode(sent).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('hello world!')\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with FairSeq pytorch modules for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hallo Welt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model')\n",
    "en2de.translate('Hello world', beam=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 9.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pilzsuppe'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2de.translate('mushroom soup', beam=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pretrained English BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n",
      "100%|| 3699866548/3699866548 [04:34<00:00, 13476771.27B/s]\n",
      "1042301B [00:00, 1168081.82B/s]\n",
      "456318B [00:00, 749710.69B/s]\n"
     ]
    }
   ],
   "source": [
    "bart = torch.hub.load('pytorch/fairseq', 'bart.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BARTHubInterface(\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = bart.encode('BART is a seq2seq model.', 'BART is not sequence to sequence.')\n",
    "last_layer_features = bart.extract_features(tokens)\n",
    "# bart.predict('mnli', tokens).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BART is a seq2seq model.BART is not sequence to sequence.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the experiment implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-01e561fa5054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodeSearchNet_RawDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslationExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/my_shared/notebooks/src/dataset_loaders.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpus_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0museful_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_split_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonl_dir_to_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/my_shared/notebooks/src/useful_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m  \u001b[0mheapq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mheappush\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheappop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsmallest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jsonlines'"
     ]
    }
   ],
   "source": [
    "from src.dataset_loaders import CodeSearchNet_RawDataLoader\n",
    "from src.Experiments import TranslationExperiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e705cad2b8c45c5b1a811e70772ad3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118fe7e4dbb84a2795f3839d9ee5b850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efb4b07f1234118a806ecf2342a0596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "codeSearchNet_data_loader = CodeSearchNet_RawDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pairs = codeSearchNet_data_loader.english_to_code_for_translation(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = codeSearchNet_data_loader.english_to_code_for_translation(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_experiment = TranslationExperiment(validation_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_translate(src):\n",
    "    return \"return output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translation_experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-99711cebda9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslation_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_translate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'translation_experiment' is not defined"
     ]
    }
   ],
   "source": [
    "translation_experiment.evaluate(simple_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "for i in reversed(range(len(a))):\n",
    "    print(i)\n",
    "    if a[i] == 3:\n",
    "        del a[i]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,len(a)))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a translation data processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DataProcessors import DataProcessor, ByteLevelBPETokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tqdm.notebook as tqdm \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeTrainedBPE_Translation_DataProcessor(DataProcessor, Dataset):\n",
    "    def __init__(self, task_data, max_src_len=512, max_tgt_len=512):\n",
    "        \"\"\"\n",
    "        This data processor tokenizes and numericalises using a custom byte pair \n",
    "        encoding trained on the codeSearchNet train data with full docstrings.\n",
    "        \"\"\"\n",
    "        self.task_data = task_data\n",
    "        self.max_src_len = max_src_len\n",
    "        self.max_tgt_len = max_tgt_len\n",
    "        self.tokenizer = ByteLevelBPETokenizer(\"/nfs/phd_by_carlos/notebooks/datasets/code_search_net/code_bpe_hugging_32k-vocab.json\",\n",
    "                                          \"/nfs/phd_by_carlos/notebooks/datasets/code_search_net/code_bpe_hugging_32k-merges.txt\")\n",
    "        self.tokenizer.add_special_tokens([\"[CLS]\", \"[EOS]\", \"[PAD]\"])\n",
    "        self.EOS = self.tokenizer.encode(\"[EOS]\").ids[0]\n",
    "        self.PAD = self.tokenizer.encode(\"[PAD]\").ids[0]\n",
    "        self.CLS = self.tokenizer.encode(\"[CLS]\").ids[0]\n",
    "        \n",
    "        self.vocab_size = self.tokenizer.get_vocab_size()\n",
    "        self.__remove_long_samples()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.task_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.task_data[idx]\n",
    "        sample = {'src': self.encode(src), 'tgt': self.encode(tgt)}\n",
    "        return sample\n",
    "    \n",
    "    def __remove_long_samples(self):\n",
    "        for i in tqdm.tqdm(list(reversed(range(len(self.task_data)))), desc=\"removing long samples\"):\n",
    "            src, tgt = self.task_data[i]\n",
    "            if len(self.encode(src))>self.max_src_len or len(self.encode(tgt))>self.max_tgt_len:\n",
    "                del self.task_data[i]\n",
    "        \n",
    "    def encode(self, sample):\n",
    "        \"\"\"\n",
    "        sample: str: the input string to encode\n",
    "        \"\"\"\n",
    "        return self.tokenizer.encode(sample).ids + [self.EOS]\n",
    "        \n",
    "    def encode_to_tensor(self,input_samples):\n",
    "        \"\"\"\n",
    "        input_samples: [str]: one or more strings to convert to a single padded tensor. (Seq_len x batch)\n",
    "        \"\"\"\n",
    "        return pad_sequence([torch.Tensor(self.encode(sample)).type(torch.LongTensor) for sample in input_samples], padding_value=self.PAD)\n",
    "    \n",
    "    def collate(self, input_samples):\n",
    "        \"\"\"\n",
    "        numerical_sample: [int]\n",
    "        \"\"\"\n",
    "        collated_samples = {}\n",
    "        sample_keys = input_samples[0].keys()\n",
    "        for key in sample_keys:\n",
    "            collated_samples[key] = pad_sequence([torch.Tensor(sample[key]).type(torch.LongTensor) for sample in input_samples], \n",
    "                                                 padding_value=self.PAD)\n",
    "        return collated_samples\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        \"\"\"\n",
    "        ids: [int]: ids to decode\n",
    "        \"\"\"\n",
    "        return self.tokenizer.decode(ids)\n",
    "    \n",
    "    def decode_tensor(self, output_tensor):\n",
    "        \"\"\"\n",
    "        output_tensor: [[int]]: model output (Seq_len x batch)\n",
    "        \"\"\"\n",
    "        batch_first_output_tensor = output_tensor.T\n",
    "        return [self.decode(sequence.cpu().tolist()) for sequence in batch_first_output_tensor]\n",
    "        \n",
    "    def to_dataloader(self, batch_size, repeat=False, num_workers=4, shuffle=True):\n",
    "        return DataLoader(self, batch_size=batch_size, num_workers=num_workers,\\\n",
    "                           drop_last=False, collate_fn = self.collate, shuffle=shuffle)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15f8ec396c4438c910a16f1738b0b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='removing long samples', max=23107.0, style=ProgressStyle("
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BPE_processor = CodeTrainedBPE_Translation_DataProcessor(validation_pairs, max_tgt_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a test', 'another one']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = BPE_processor.encode_to_tensor([\"this is a test\",\"another one\"])\n",
    "BPE_processor.decode_tensor(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': [5390, 1436, 2351, 331, 2774, 2857, 4873, 2019, 6774, 3634, 1461, 1141, 1436, 2326, 1536, 348, 32001], 'tgt': [334, 587, 62, 2143, 62, 5895, 7, 361, 314, 198, 258, 329, 198, 1691, 198, 258, 329, 198, 258, 304, 3100, 7, 361, 314, 198, 260, 340, 491, 198, 258, 674, 491, 292, 2550, 25, 198, 260, 340, 2550, 58, 361, 60, 198, 258, 461, 25, 198, 260, 547, 942, 396, 4857, 2019, 664, 25, 3027, 551, 7, 361, 390, 32001]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(BPE_processor)):\n",
    "    sample = BPE_processor[i]\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  334,   334],\n",
      "        [ 3828,   587],\n",
      "        [    7,    62],\n",
      "        [ 1019,  1970],\n",
      "        [   11,  2682],\n",
      "        [  691,    62],\n",
      "        [  565,  1107],\n",
      "        [  314,     7],\n",
      "        [  198,  1353],\n",
      "        [  258,    28],\n",
      "        [  329,   362],\n",
      "        [  198,    11],\n",
      "        [ 1691,   691],\n",
      "        [  258,   565],\n",
      "        [  329,   314],\n",
      "        [  198,   198],\n",
      "        [  258,   258],\n",
      "        [  304,   329],\n",
      "        [  768,   198],\n",
      "        [    7,  1691],\n",
      "        [ 1019,   258],\n",
      "        [   11,   329],\n",
      "        [  732,   198],\n",
      "        [  314,   258],\n",
      "        [  198,  1684],\n",
      "        [  260,    62],\n",
      "        [ 1379,  2682],\n",
      "        [  272,    28],\n",
      "        [ 6381,   565],\n",
      "        [    7,    13],\n",
      "        [ 1019,  1359],\n",
      "        [    8,   396],\n",
      "        [  198,  1970],\n",
      "        [  258,    62],\n",
      "        [  304,  2682],\n",
      "        [ 1814,   433],\n",
      "        [    7,   198],\n",
      "        [ 1019,   258],\n",
      "        [   11,   954],\n",
      "        [ 4503,   394],\n",
      "        [  600,   361],\n",
      "        [12752,   395],\n",
      "        [  421,   272],\n",
      "        [  309,  1684],\n",
      "        [ 1401,    62],\n",
      "        [    6,  2682],\n",
      "        [  292,   198],\n",
      "        [  954,   258],\n",
      "        [   25,   340],\n",
      "        [  198,  1684],\n",
      "        [  260,    62],\n",
      "        [ 1462,   411],\n",
      "        [  272,     7],\n",
      "        [17146,  1353],\n",
      "        [  198,    13],\n",
      "        [  258,  6813],\n",
      "        [  461,  1268],\n",
      "        [   25,  1970],\n",
      "        [  198,  4638],\n",
      "        [  260,  3732],\n",
      "        [ 1462,  1268],\n",
      "        [  272,  1107],\n",
      "        [17146,  1313],\n",
      "        [ 3592,   198],\n",
      "        [  198,   563],\n",
      "        [  198,   559],\n",
      "        [  258,    62],\n",
      "        [  340,   361],\n",
      "        [ 1462,   604],\n",
      "        [    7,  1107],\n",
      "        [ 1019,   377],\n",
      "        [   11,   691],\n",
      "        [  691,   565],\n",
      "        [  565,     8],\n",
      "        [    8, 32001],\n",
      "        [32001, 32002]])\n",
      "['def progress(iter, **kwargs):\\n    \"\"\"\\n    \\n    \"\"\"\\n    if isinstance(iter, int):\\n        iter = xrange(iter)\\n    if hasattr(iter, \\'__len__\\') or \\'target\\' in kwargs:\\n        cls = Progress\\n    else:\\n        cls = ProgressBase\\n\\n    return cls(iter, **kwargs)', 'def get_serviceaccount_keys(client=None, **kwargs):\\n    \"\"\"\\n    \\n    \"\"\"\\n    service_account=kwargs.pop(\\'service_account\\')\\n    kwargs[\\'name\\'] = service_account\\n    return service_list(client.projects().serviceAccounts().keys(),\\n                        key_name=\\'keys\\', **kwargs)']\n"
     ]
    }
   ],
   "source": [
    "dataloader = BPE_processor.to_dataloader(2)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(sample_batched[\"tgt\"])\n",
    "    print(BPE_processor.decode_tensor(sample_batched[\"tgt\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-283-be147a098ed0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-283-be147a098ed0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The gloomy night was cold and damp\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The gloomy night was cold and damp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloomy = [0,1,1]\n",
    "dark   = [0,1,0]\n",
    "night  = [1,2,-1]\n",
    "cold   = [0,2,1]\n",
    "damp   = [1,2,1]\n",
    "ice    = [1,2,0]\n",
    "the    = [-1,0,-2]\n",
    "was    = [3,0,-1]\n",
    "_and   = [-2,-1,0]\n",
    "at     = [-2,0,-2]\n",
    "\n",
    "context_embedding = torch.mean(torch.Tensor([dark, gloomy, was, cold]), dim=0)\n",
    "print(f\"Context embedding: {context_embedding}\")\n",
    "upscale_embedding = torch.Tensor([gloomy, dark, night, cold, damp, ice, the, was, _and, at])\n",
    "logits = torch.matmul(upscale_embedding, context_embedding.T)\n",
    "print(f\"Per token dot product: {logits}\")\n",
    "probs = logits.softmax(0)\n",
    "print(f\"Per token probabillities {probs}\")\n",
    "print(f\"Prob for 'night': {probs[2]:0.2f}\")\n",
    "print(f\"Prob for 'and': {probs[8]:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5000,  0.7500, -0.2500])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  0., -2.],\n",
       "        [ 0.,  1.,  1.],\n",
       "        [ 3.,  0.,  1.],\n",
       "        [ 0.,  2.,  1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([the, gloomy, was, cold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "the       = torch.Tensor([0,1])\n",
    "president = torch.Tensor([1,-1])\n",
    "of        = torch.Tensor([1,2])\n",
    "the       = torch.Tensor([0,1])\n",
    "european  = torch.Tensor([1,2])\n",
    "union     = torch.Tensor([1,2])\n",
    "spoke     = torch.Tensor([2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_q = torch.Tensor([[-1,2],\n",
    "                    [0,-1]])\n",
    "w_k = torch.Tensor([[0,1],\n",
    "                    [1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.,  1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(w_q, president.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(w_k, spoke.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.matmul(w_q, president.T), torch.matmul(w_k, the.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.,  3.]), tensor([0., 2.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(president, w_q), torch.matmul(spoke, w_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.matmul(president, w_q), torch.matmul(spoke, w_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced experimental pipeline demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b6d26058324f8dbfa0ad6758edcbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a8e04c84f044f4967b5f3b8facd54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a2931616d54b0796c30ce8154f8c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_loaders import CodeSearchNet_RawDataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "codeSearchNet_data_loader = CodeSearchNet_RawDataLoader()\n",
    "validation_pairs = codeSearchNet_data_loader.english_to_code_for_translation(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.copy_gen_transformer import CopyGeneratorTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CopyGeneratorTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.src_embedder.word_embeddings.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with D3.js\n",
    "this will only work with the classic notetbook style, unfortunately.\n",
    "\n",
    "see: https://www.stefaanlippens.net/jupyter-custom-d3-visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript, HTML\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({paths: {d3: 'https://d3js.org/d3.v5.min'}});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "// First undefine 'circles' so we can easily reload this file.\n",
       "require.undef('circles');\n",
       "\n",
       "define('circles', ['d3'], function (d3) {\n",
       "\n",
       "    function draw(container, data, width, height) {\n",
       "        width = width || 600;\n",
       "        height = height || 200;\n",
       "        var svg = d3.select(container).append(\"svg\")\n",
       "            .attr('width', width)\n",
       "            .attr('height', height)\n",
       "            .append(\"g\");\n",
       "\n",
       "        var x = d3.scaleLinear()\n",
       "            .domain([0, data.length - 1])\n",
       "            .range([50, width - 50]);\n",
       "\n",
       "        var circles = svg.selectAll('circle').data(data);\n",
       "\n",
       "        circles.enter()\n",
       "            .append('circle')\n",
       "            .attr(\"cx\", function (d, i) {return x(i);})\n",
       "            .attr(\"cy\", height / 2)\n",
       "            .attr(\"r\", 20)\n",
       "            .style(\"fill\", \"#1f77b4\")\n",
       "            .style(\"opacity\", 0.7)\n",
       "            .on('mouseover', function() {\n",
       "                d3.select(this)\n",
       "                  .interrupt('fade')\n",
       "                  .style('fill', '#ff850e')\n",
       "                  .style(\"opacity\", 1)\n",
       "                  .attr(\"r\", function (d) {return 1.1 * d + 10;});\n",
       "            })\n",
       "            .on('mouseout', function() {\n",
       "                d3.select(this)\n",
       "                    .transition('fade').duration(500)\n",
       "                    .style(\"fill\", \"#1f77b4\")\n",
       "                    .style(\"opacity\", 0.7)\n",
       "                    .attr(\"r\", function (d) {return d;});\n",
       "            })\n",
       "            .transition().duration(2000)\n",
       "            .attr(\"r\", function (d) {return d;});\n",
       "    }\n",
       "\n",
       "    return draw;\n",
       "});\n",
       "\n",
       "element.append('<small>&#x25C9; &#x25CB; &#x25EF; Loaded circles.js &#x25CC; &#x25CE; &#x25CF;</small>');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "svg circle {\n",
       "  stroke: #16527b;\n",
       "  stroke-width: 1px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Javascript(\"require.config({paths: {d3: 'https://d3js.org/d3.v5.min'}});\"))\n",
    "display(Javascript(filename=\"./src/visualisation/circles.js\"))\n",
    "display(HTML(filename=\"./src/visualisation/circles.css.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(data, width=600, height=400):\n",
    "    display(Javascript(\"\"\"\n",
    "        (function(element){\n",
    "            require(['circles'], function(circles) {\n",
    "                circles(element.get(0), %s, %d, %d);\n",
    "            });\n",
    "        })(element);\n",
    "    \"\"\" % (json.dumps(data), width, height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_circles([10, 60, 40, 5, 30, 10], width=500, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodinGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WALL():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"W\"\n",
    "    @property\n",
    "    def proximity_reward(self):\n",
    "        return -0\n",
    "\n",
    "class FLOOR():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" \"\n",
    "    @property\n",
    "    def proximity_reward(self):\n",
    "        return 0\n",
    "\n",
    "class ENEMY_PAC():\n",
    "    def __init__(self, ID, type_ID, speed_turns_left, ability_cooldown):\n",
    "        self.ID = ID\n",
    "        self.type_ID = type_ID\n",
    "        self.speed_turns_left = speed_turns_left\n",
    "        self.ability_cooldown = ability_cooldown\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"E\"\n",
    "\n",
    "    @property\n",
    "    def proximity_reward(self):\n",
    "        return 4\n",
    "\n",
    "class FRIEND_PAC():\n",
    "    def __init__(self, ID, type_ID, speed_turns_left, ability_cooldown):\n",
    "        self.ID = ID\n",
    "        self.type_ID = type_ID\n",
    "        self.speed_turns_left = speed_turns_left\n",
    "        self.ability_cooldown = ability_cooldown\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"F\"\n",
    "\n",
    "    @property\n",
    "    def proximity_reward(self):\n",
    "        return -10\n",
    "\n",
    "class PELLET():\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    @property\n",
    "    def proximity_reward(self):\n",
    "        return self.value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"o\" if self.value > 1 else \".\"\n",
    "\n",
    "def print_arena(arena):\n",
    "    arena_str = \"\"\n",
    "    for row in arena:\n",
    "        for tile in row:\n",
    "            arena_str += str(tile)\n",
    "        arena_str += \"\\n\"\n",
    "    print(arena_str, file=sys.stderr)\n",
    "    return arena_str\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_arena = '''WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
    "WWW   W W W W       W W W WEo WWW\n",
    "WWWWW W W W W W W W W W W WFWWWWW\n",
    "      W W     W   W     W W      \n",
    "WWWWW W WWW W WWWWW W WWW W WWWWW\n",
    "W           W       W           W\n",
    "W W WWW WWW WWWWWWWWW WWW WWW W W\n",
    "W W   W W               W W   W W\n",
    "W WWW W W WWWWW W WWWWW W W WWW W\n",
    "W       W W....F      W W       W\n",
    "W WWWWW W W WWW WFWWW W W WWWWW W\n",
    "W     W       W   W       W     W\n",
    "WWW W W W W W WoWoW W W W W W WWW\n",
    "WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW'''\n",
    "def txt_to_arena(txt):\n",
    "    txt_rows = txt.split('\\n')\n",
    "    arena = []\n",
    "    for row in txt_rows:\n",
    "        arena.append([])\n",
    "        for ch in row:\n",
    "            if ch ==\"W\":\n",
    "                arena[-1].append(WALL())\n",
    "            if ch ==\" \":\n",
    "                arena[-1].append(FLOOR())\n",
    "            if ch ==\"E\":\n",
    "                arena[-1].append(ENEMY_PAC(0,0,0,0))\n",
    "            if ch ==\"F\":\n",
    "                arena[-1].append(FRIEND_PAC(0,0,0,0))\n",
    "            if ch ==\".\":\n",
    "                arena[-1].append(PELLET(1))\n",
    "            if ch ==\"o\":\n",
    "                arena[-1].append(PELLET(10))\n",
    "    return arena\n",
    "arena = txt_to_arena(txt_arena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.59 ms, sys: 0 ns, total: 8.59 ms\n",
      "Wall time: 8.49 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class VALUE_FUNCTION():\n",
    "    def __init__(self, arena, gamma=0.9, iterations=5):\n",
    "        self.height, self.width = len(arena), len(arena[0])\n",
    "        self.value_grid = np.zeros((self.height, self.width))\n",
    "        \n",
    "        # value iteration\n",
    "        for iters in range(iterations):\n",
    "            for x in range(self.width):\n",
    "                for y in range(self.height):\n",
    "                    if isinstance(arena[y][x], WALL):\n",
    "                        self.value_grid[y,x] = arena[y][x].proximity_reward\n",
    "                    else:\n",
    "                        self.value_grid[y,x] = max([arena[y][x].proximity_reward + gamma*self.value_grid[(y+dy)%self.height,(x+dx)%self.width] for dy, dx in [(1,0),(-1,0),(0,1),(0,-1)]])\n",
    "                    \n",
    "    def true_coords(self, x, y):\n",
    "        \n",
    "        return x%self.width, y%self.height\n",
    "    \n",
    "    def __call__(self, x, y):\n",
    "        return self.value_grid[y, x]\n",
    "\n",
    "value_fn = VALUE_FUNCTION(arena,iterations=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff50fabfdd8>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(value_fn.value_grid + 2*np.random.random(value_fn.value_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff5125b8908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(value_fn.value_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [(1,0),(-1,0),(0,1),(0,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.pop(foo.index((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24691358024691354"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.var([(1,2),(1,3),(1,2),(1,3),(1,2),(1,3),(1,2),(1,3),(1,2)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.86274247e-01, 7.22083021e-01, 9.39475735e-01, 7.72741290e-01,\n",
       "        3.75023371e-01, 4.15317452e-01, 3.87466789e-02, 8.89286419e-01,\n",
       "        9.25134322e-01, 9.40347713e-01, 3.89407153e-01, 3.27474912e-01,\n",
       "        7.57066414e-01, 9.66476822e-01, 6.56446718e-01, 4.77709545e-01,\n",
       "        5.16878908e-01, 1.85709977e-01, 8.23868418e-01, 3.35737082e-01,\n",
       "        4.64760245e-02, 7.30596133e-01, 4.20478010e-01, 9.40175707e-01,\n",
       "        3.89219567e-01, 9.72387190e-01, 7.65386896e-01, 8.49933122e-01,\n",
       "        3.50411050e-01, 1.86109826e-01, 2.59098720e-01],\n",
       "       [8.45346547e-01, 5.67704255e-01, 2.32885560e-01, 2.50457977e+01,\n",
       "        5.03831423e-01, 5.69598714e+01, 6.35719232e+01, 6.92433526e+01,\n",
       "        8.18721843e-01, 5.37786085e+01, 9.68363111e-01, 4.91611285e+01,\n",
       "        1.53540004e-01, 4.39370359e+01, 4.23394655e+01, 4.01894447e+01,\n",
       "        3.75524924e+01, 3.57633370e+01, 7.48883213e-01, 3.34636348e+01,\n",
       "        9.08714695e-01, 4.66793590e+01, 4.31949140e-01, 7.57404906e+01,\n",
       "        7.16894858e+01, 6.79862535e+01, 9.32846664e-01, 3.37301439e+01,\n",
       "        9.40880299e-01, 1.48567063e-01, 6.08627766e-01],\n",
       "       [1.34087904e-01, 7.10758895e-01, 7.35701309e-01, 2.93550570e+01,\n",
       "        2.11951869e-02, 2.74397197e-02, 1.16800617e-01, 7.62147094e+01,\n",
       "        7.12161209e-01, 6.00035345e+01, 7.80559749e-01, 5.36573953e+01,\n",
       "        1.04613587e-01, 4.88625518e+01, 6.45790905e-01, 3.75707717e+01,\n",
       "        8.21118503e-01, 3.42862670e+01, 3.10485241e-01, 3.97726164e+01,\n",
       "        4.03992990e-01, 5.18301150e+01, 1.65695365e-01, 8.29429052e+01,\n",
       "        8.92690475e-01, 1.97739710e-01, 9.39765548e-01, 3.78969971e+01,\n",
       "        4.59816461e-01, 4.38119733e-01, 6.42217267e-01],\n",
       "       [2.66427618e+01, 2.49513218e+01, 2.92935104e+01, 3.50727331e+01,\n",
       "        5.99592799e-01, 6.01644311e+01, 6.60203541e+01, 7.19881577e+01,\n",
       "        6.82359802e+01, 6.51978519e+01, 6.17598589e+01, 5.92446769e+01,\n",
       "        5.55719008e+01, 5.28547940e+01, 4.67983463e-01, 3.63547385e+01,\n",
       "        1.48096986e-01, 3.37914159e+01, 3.97293485e+01, 4.48487837e+01,\n",
       "        5.11618149e+01, 5.74808002e+01, 7.37373471e+01, 7.93984902e+01,\n",
       "        6.63160127e+01, 6.29071997e+01, 7.03437323e-01, 4.31270398e+01,\n",
       "        4.08925658e+01, 3.83280627e+01, 4.09644638e+01],\n",
       "       [1.83968292e-01, 4.75319258e-01, 3.32793083e-01, 3.84414961e+01,\n",
       "        2.33961353e-01, 5.70560446e+01, 7.33726769e-01, 6.84202924e+01,\n",
       "        5.10162290e-01, 6.18687806e+01, 9.77114357e-01, 5.59392722e+01,\n",
       "        8.82513618e-01, 6.98315587e-01, 7.39615651e-01, 3.45468232e+01,\n",
       "        2.68313741e-01, 1.70352951e-01, 8.67965840e-01, 4.31847533e+01,\n",
       "        5.77070881e-01, 5.56439419e+01, 6.60036616e-01, 7.55712708e+01,\n",
       "        1.94115023e-01, 5.92141242e+01, 1.75380050e-01, 4.66572468e+01,\n",
       "        7.01938639e-01, 5.63523169e-01, 8.05418635e-01],\n",
       "       [1.46553558e-01, 3.32831888e+01, 3.85184794e+01, 4.40788184e+01,\n",
       "        4.87763036e+01, 5.45320323e+01, 1.74643221e-01, 6.55487638e+01,\n",
       "        6.15955133e+01, 5.89618906e+01, 6.16157788e-01, 5.33697913e+01,\n",
       "        5.07860431e+01, 4.80056322e+01, 5.02877338e-01, 3.23256127e+01,\n",
       "        8.55712890e-01, 3.06340162e+01, 3.53888399e+01, 4.10371545e+01,\n",
       "        7.22429706e-02, 6.08432080e+01, 6.62323905e+01, 7.18559049e+01,\n",
       "        3.45461959e-02, 5.69171344e+01, 5.40802257e+01, 5.08941218e+01,\n",
       "        4.82719075e+01, 4.60557288e+01, 4.01345892e-01],\n",
       "       [5.44429489e-01, 3.18234525e+01, 5.46506076e-01, 7.88886399e-01,\n",
       "        4.43941672e-01, 5.16249220e+01, 7.71072764e-01, 9.16194850e-01,\n",
       "        1.44316064e-01, 5.62910514e+01, 1.90094223e-01, 5.08431071e+01,\n",
       "        4.41940355e-01, 4.61872656e+01, 9.43136829e-02, 3.59394719e+01,\n",
       "        3.95030976e-01, 3.20364691e+01, 6.18314220e-01, 3.92405895e+01,\n",
       "        8.34728498e-01, 5.90991090e+01, 6.24784488e-02, 2.46619092e-01,\n",
       "        7.34586921e-01, 5.35045143e+01, 7.91488948e-01, 1.35178358e-01,\n",
       "        5.87695390e-02, 4.37435151e+01, 1.78650109e-01],\n",
       "       [5.32879666e-02, 3.02338906e+01, 3.81827007e-01, 3.97889336e+01,\n",
       "        4.39591423e+01, 4.86517628e+01, 8.42252859e-01, 4.49863100e+01,\n",
       "        4.86307866e+01, 5.35593669e+01, 8.02743412e-01, 4.78936131e+01,\n",
       "        1.28199817e-01, 4.31204383e+01, 4.09587248e+01, 3.89783200e+01,\n",
       "        3.76304147e+01, 3.51511664e+01, 9.81568314e-01, 3.67204142e+01,\n",
       "        3.05833755e-01, 5.71828688e+01, 5.43872526e+01, 5.17614679e+01,\n",
       "        9.15177701e-01, 5.13751105e+01, 4.86848993e+01, 4.60484567e+01,\n",
       "        2.93721826e-01, 4.17430660e+01, 5.80525126e-01],\n",
       "       [7.07848999e-01, 2.86968481e+01, 3.09818669e-01, 3.78731870e+01,\n",
       "        1.51878997e-01, 4.65504009e+01, 9.24105253e-01, 4.37203015e+01,\n",
       "        8.79170070e-01, 1.17755922e-01, 6.35426377e-01, 4.57729845e+01,\n",
       "        8.04607891e-01, 6.05589466e-01, 6.56656153e-01, 3.71919481e+01,\n",
       "        7.67307855e-01, 3.34967208e-01, 1.74363203e-01, 3.51019843e+01,\n",
       "        5.21857570e-01, 7.92092224e-01, 9.10917331e-01, 4.87235985e+01,\n",
       "        2.14150232e-01, 4.85187898e+01, 3.28735043e-02, 4.38776486e+01,\n",
       "        7.15570163e-02, 4.01221071e+01, 9.38902913e-01],\n",
       "       [3.06720893e-01, 2.74841043e+01, 8.51782114e-01, 3.52337260e+01,\n",
       "        3.01122256e-01, 4.41840168e+01, 4.16495958e+01, 4.21310543e+01,\n",
       "        3.94665007e+01, 3.80802093e+01, 3.97059093e+01, 4.30152541e+01,\n",
       "        4.14195091e+01, 3.89380526e+01, 3.72795834e+01, 3.52388781e+01,\n",
       "        3.33757928e+01, 3.18388902e+01, 3.06200255e+01, 3.36409738e+01,\n",
       "        3.35122940e+01, 3.76230317e+01, 4.21683023e+01, 4.65346370e+01,\n",
       "        4.38977058e+01, 4.58123068e+01, 8.07310902e-01, 4.12040131e+01,\n",
       "        8.84303826e-01, 3.80627971e+01, 6.92701432e-01],\n",
       "       [2.72594837e-01, 2.60877895e+01, 2.20251806e-02, 3.39775493e+01,\n",
       "        1.94727944e-01, 2.67654083e-01, 4.45352605e-01, 3.99536302e+01,\n",
       "        9.29056039e-02, 3.64229556e+01, 2.56262295e-01, 4.17438253e+01,\n",
       "        6.60284700e-01, 1.75250495e-01, 1.18786989e-01, 3.41511870e+01,\n",
       "        4.49532564e-02, 6.27989960e-01, 6.56530498e-01, 3.20502597e+01,\n",
       "        5.10271748e-02, 3.97189708e+01, 4.44940984e-01, 5.14292051e+01,\n",
       "        2.56790456e-01, 9.43850990e-01, 3.31993000e-01, 3.95742594e+01,\n",
       "        5.64296528e-01, 3.54324422e+01, 1.92749704e-01],\n",
       "       [5.86255607e-01, 2.48188126e+01, 2.85768206e+01, 3.20978362e+01,\n",
       "        5.21449888e-02, 1.16472919e+01, 2.44966073e+01, 2.74448704e+01,\n",
       "        3.24002335e+01, 3.55950538e+01, 4.27899481e-01, 3.96160046e+01,\n",
       "        3.71037886e+01, 3.55223122e+01, 9.88332422e-01, 3.23818388e+01,\n",
       "        8.22524835e-01, 2.21686072e+01, 2.67353722e+01, 2.99856659e+01,\n",
       "        4.54643403e-01, 4.53634441e+01, 5.17394026e+01, 5.81262569e+01,\n",
       "        6.36827876e+01, 7.03601754e+01, 2.75295218e-01, 3.72119873e+01,\n",
       "        3.55645359e+01, 3.43106755e+01, 4.91541010e-01],\n",
       "       [7.20423080e-01, 1.61487084e-01, 3.46107041e-02, 3.03059957e+01,\n",
       "        1.48764542e-01, 2.10388202e+01, 3.40058686e-01, 2.72740475e+01,\n",
       "        4.57715236e-01, 2.88844853e-01, 4.98975191e-01, 9.36223078e-01,\n",
       "        6.94506068e-01, 3.36030493e+01, 4.82495940e-01, 3.04002024e+01,\n",
       "        2.68325438e-01, 2.17293268e+01, 7.12114437e-01, 6.01928673e-01,\n",
       "        7.64480965e-01, 5.42099067e-01, 5.81238888e-01, 5.48121423e+01,\n",
       "        8.83810927e-01, 7.69341259e+01, 8.60606191e-01, 3.58407798e+01,\n",
       "        3.49280598e-01, 6.75349652e-01, 1.27238232e-02],\n",
       "       [7.31611967e-01, 6.75920288e-01, 7.23405018e-02, 7.62359669e-01,\n",
       "        5.91662432e-01, 5.55091788e-01, 2.27019323e-01, 5.62947945e-01,\n",
       "        2.56436097e-01, 2.45843886e-01, 1.84597640e-01, 8.48026118e-01,\n",
       "        5.11181450e-01, 5.15139097e-02, 2.21542141e-01, 9.73695576e-01,\n",
       "        3.15774687e-01, 2.57221428e-01, 6.85591523e-01, 1.99333965e-01,\n",
       "        3.22299293e-01, 5.01886293e-01, 3.66051509e-01, 3.88743106e-01,\n",
       "        7.59092234e-02, 7.17245250e-01, 9.59647368e-01, 7.99739839e-01,\n",
       "        4.45158663e-01, 2.42383468e-01, 4.27793961e-01]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_fn.value_grid + np.random.random(value_fn.value_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-6a308901b3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "(1,2)-(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3584: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-9691e4f59804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34mf\"MOVE {4} {5} {6} {sum(np.var([],axis=0))}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "f\"MOVE {4} {5} {6} {sum(np.var([],axis=0))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Nave bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    (\"it's a lovely day\", \"happy\"),\n",
    "    (\"this meal is delicious\", \"happy\"),\n",
    "    (\"i like cycling\", \"happy\"),\n",
    "    (\"the food is burnt\", \"sad\"),\n",
    "    (\"time goes too quickly\", \"sad\"),\n",
    "    (\"carolina is far away\", \"sad\"),\n",
    "    (\"Trump is an asshole\", \"angry\"),\n",
    "    (\"I can't find my t-shirt!\", \"angry\"),\n",
    "    (\"They stole my bycicle\", \"angry\"),\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"my grandmother died\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Mark: the automatic marker\n",
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer.high_level as high_level\n",
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "# wv = api.load('word2vec-google-news-300')\n",
    "from transformers import BertModel, BertForMaskedLM, BertConfig,BertTokenizer, PreTrainedEncoderDecoder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tqdm.notebook as tqdm \n",
    "from src.dataset_loaders import RawDataLoader\n",
    "from src.DataProcessors import DataProcessor\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.activation import MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_base_path = \"./datasets/TAD_Marking/\"\n",
    "file_names = [f for f in listdir(mypath) if isfile(join(mypath, f)) and \".pdf\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83edb3cae1a44f23a11b81803dcf0c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "multi_PDF_data = []\n",
    "for name in tqdm.tqdm(file_names):\n",
    "    pdf_text = high_level.extract_text(join(pdf_base_path, name))\n",
    "    multi_PDF_data.append(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_paragraphs = pdf_text.split(\"\\n\\n\")\n",
    "pdf_paragraphs = [x for x in pdf_paragraphs if len(x.split(\" \")) > 10 or re.match(r\"Q[1-5]\", x, re.IGNORECASE)]\n",
    "len(pdf_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27, 51, 70, 29, 7, 114, 18, 35, 96, 28, 68, 22, 30, 39, 50, 65, 28, 61, 52, 29, 26, 150, 23, 105, 64, 148, 28, 55, 43, 32, 8, 48, 33, 28, 7, 20, 35, 16, 22, 25, 89, 10, 47, 71, 26, 75, 23, 45, 35, 17, "
     ]
    }
   ],
   "source": [
    "for pdf_text in multi_PDF_data:\n",
    "    pdf_paragraphs = pdf_text.split(\"\\n\\n\")\n",
    "    pdf_paragraphs = [x for x in pdf_paragraphs if len(x.split(\" \")) > 10 or re.match(r\"Q[1-5]\", x, re.IGNORECASE)]\n",
    "    print(len(pdf_paragraphs), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/TAD_Marking/marks.tsv') as tsvfile:\n",
    "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
    "    results = {}\n",
    "    for l in reader:\n",
    "        results[l[\"GUID\"]] = list(l.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAD_PDF_RawDataLoader(RawDataLoader):\n",
    "    def __init__(self, data_directory=\"./datasets/TAD_Marking/\"):\n",
    "        file_names = [f for f in listdir(data_directory) if isfile(join(data_directory, f)) and \".pdf\" in f]\n",
    "        multi_PDF_data = []\n",
    "        for name in tqdm.tqdm(file_names):\n",
    "            pdf_text = high_level.extract_text(join(pdf_base_path, name))\n",
    "            multi_PDF_data.append(pdf_text)\n",
    "            \n",
    "        self.max_scores = [7,4,5,5,11,3]\n",
    "            \n",
    "        with open('datasets/TAD_Marking/marks.tsv') as tsvfile:\n",
    "            reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
    "            self.results = {}\n",
    "            for l in reader:\n",
    "                self.results[l[\"GUID\"]] = list(l.values())\n",
    "        \n",
    "        valid_index = int(len(multi_PDF_data)*0.8)\n",
    "        test_index = int(len(multi_PDF_data)*0.9)\n",
    "        self.train_split = multi_PDF_data[:valid_index]\n",
    "        self.valid_split = multi_PDF_data[valid_index:test_index]\n",
    "        self.test_split = multi_PDF_data[test_index:]\n",
    "        \n",
    "    \n",
    "    def _get_split(self, split):\n",
    "        if split==\"train\":\n",
    "            return self.train_split\n",
    "        elif split==\"valid\":\n",
    "            return self.valid_split\n",
    "        elif split==\"test\":\n",
    "            return self.test_split\n",
    "        elif split==\"all\":\n",
    "            return self.train_split + self.valid_split + self.test_split\n",
    "        else:\n",
    "            raise Exception(f\"'{split}' split not recognised.\")\n",
    "    \n",
    "    def paragraphs_for_multi_regression(self, split, size=sys.maxsize, full_docstring=False):\n",
    "        \"\"\"\n",
    "        This method returns a standard format of [(source_str, target_str)] used for translation.\n",
    "        \n",
    "        split: str: \"train\", \"valid\", \"test\", \"all\"\n",
    "        \"\"\"\n",
    "        data_split = self._get_split(split)\n",
    "        separated_paragraphs = []\n",
    "        for pdf_text in data_split:\n",
    "            word_set = set(pdf_text.lower().replace(\"\\n\", \" \").split(\" \"))\n",
    "            GUID = None\n",
    "            for key in self.results.keys():\n",
    "                if key.lower() in word_set:\n",
    "                    GUID = key\n",
    "                    break\n",
    "            if GUID == None:\n",
    "                continue\n",
    "            \n",
    "            pdf_paragraphs = pdf_text.split(\"\\n\\n\")\n",
    "            pdf_paragraphs = [x for x in pdf_paragraphs if len(x.split(\" \")) > 10 or re.match(r\"Q[1-5]\", x, re.IGNORECASE)]\n",
    "            \n",
    "            sample = {}\n",
    "            sample[\"paragraphs\"] = pdf_paragraphs\n",
    "            normalized_scores = [float(s)/m for s, m in zip(self.results[GUID][1:7], self.max_scores)]\n",
    "            sample[\"scores\"] = normalized_scores\n",
    "            separated_paragraphs.append(sample)\n",
    "        return separated_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a7235a356949028685ac2a5b753f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_loader = TAD_PDF_RawDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_loader.paragraphs_for_multi_regression(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[254,\n",
       " 74,\n",
       " 68,\n",
       " 50,\n",
       " 292,\n",
       " 133,\n",
       " 58,\n",
       " 23,\n",
       " 52,\n",
       " 30,\n",
       " 16,\n",
       " 31,\n",
       " 75,\n",
       " 47,\n",
       " 444,\n",
       " 50,\n",
       " 95,\n",
       " 17,\n",
       " 48,\n",
       " 131,\n",
       " 123,\n",
       " 42,\n",
       " 30,\n",
       " 34,\n",
       " 57,\n",
       " 35,\n",
       " 39,\n",
       " 103,\n",
       " 143,\n",
       " 16,\n",
       " 41,\n",
       " 297,\n",
       " 21,\n",
       " 29,\n",
       " 85,\n",
       " 18,\n",
       " 20,\n",
       " 53,\n",
       " 82,\n",
       " 62,\n",
       " 22,\n",
       " 72,\n",
       " 61,\n",
       " 153,\n",
       " 58,\n",
       " 56,\n",
       " 58,\n",
       " 153,\n",
       " 9,\n",
       " 111,\n",
       " 22]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tok.encode(p)) for p in data[1][\"paragraphs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAD_PDF_DataProcessor(DataProcessor):\n",
    "    def __init__(self, task_data, max_paragraph_len=512, max_paragraphs=100):\n",
    "        \"\"\"\n",
    "        Things like max sequence length should be passed here and enforced elsewhere.\n",
    "        If the dataset is too large to fit, this is where the transformations will happen\n",
    "        to save the samples in a database or use IDs to make transfer faster.\n",
    "        \"\"\"\n",
    "        self.task_data = task_data\n",
    "        self.max_paragraph_len = max_paragraph_len\n",
    "        self.max_paragraphs = max_paragraphs\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.PAD = self.tokenizer.pad_token_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.task_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.task_data[idx]\n",
    "        paragraphs = sample[\"paragraphs\"]\n",
    "        scores = sample[\"scores\"]\n",
    "        sample = {'paragraphs': self.encode(paragraphs), 'scores': torch.tensor(scores)}\n",
    "        return sample\n",
    "    \n",
    "    def encode(self, paragraphs):\n",
    "        \"\"\"\n",
    "        This function needs to produce all the necessary outputs for a model \n",
    "        to only take this as input and produce a correct output.\n",
    "        \"\"\"\n",
    "        return pad_sequence([torch.Tensor(self.encode_paragraph(paragraph)).type(torch.LongTensor) for paragraph in paragraphs[:self.max_paragraphs]], padding_value=self.PAD).T\n",
    "    \n",
    "    def encode_paragraph(self, paragraph):\n",
    "        return self.tokenizer.encode(paragraph)[:self.max_paragraph_len]\n",
    "    \n",
    "    def collate(self, input_samples):\n",
    "        collated_samples = {}\n",
    "        max_pra_dims = tuple(torch.max(torch.tensor([sample[\"paragraphs\"].shape for sample in input_samples]), axis=0)[0])\n",
    "        batch = []\n",
    "        for sample in input_samples: \n",
    "            num_paras, para_length = sample[\"paragraphs\"].shape\n",
    "            padded = torch.zeros(max_pra_dims)\n",
    "            padded[:num_paras, :para_length] = sample[\"paragraphs\"]\n",
    "            batch.append(padded)\n",
    "            \n",
    "        collated_samples[\"multi_paras\"] = torch.stack(batch)\n",
    "        collated_samples[\"multi_scores\"] = torch.stack([sample[\"scores\"] for sample in input_samples])\n",
    "        return collated_samples\n",
    "    \n",
    "    def decode(self, output_tensor):\n",
    "        \"\"\"\n",
    "        This funciton should produce a correct output for the specified task, \n",
    "        it doesn't need to be the same for every transformation or task.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def to_dataloader(self, batch_size, repeat=False, num_workers=4, shuffle=True):\n",
    "        return DataLoader(self, batch_size=batch_size, num_workers=num_workers,\\\n",
    "                           drop_last=False, collate_fn = self.collate, shuffle=shuffle)\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        This should save the entire object for easy access. Saving and Loading is\n",
    "        specific to the dataProcessors.\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def load(path):\n",
    "        \"\"\"\n",
    "        STATIC METHOD\n",
    "        will load all kinds of data processors using torch.\n",
    "        \"\"\"\n",
    "        return torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TAD_PDF_DataProcessor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 444])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.__getitem__(1)[\"paragraphs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = processor.__getitem__(1)\n",
    "# s2 = processor.__getitem__(1)\n",
    "# samples = [s1,s2]\n",
    "# processor.collate(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) torch.Size([3, 6])\n",
      "tensor([[  101., 29379.,   102.,     0.,     0.,     0.],\n",
      "        [  101.,  3347.,  8670.,  2480.,   102.,     0.],\n",
      "        [  101.,  8840.,  2099.,  7861.,  7680.,   102.],\n",
      "        [    0.,     0.,     0.,     0.,     0.,     0.]]) torch.Size([4, 6])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-423-6b32af5391cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_paras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpara_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_samples' is not defined"
     ]
    }
   ],
   "source": [
    "s1 = processor.encode([\"foo\", \"bar baz\", \"lor em\", \"lor em\"])\n",
    "s2 = processor.encode([\"foo\", \"bar baz\", \"lor em sum\"])\n",
    "samples = [s1,s2]\n",
    "print(s1.shape, s2.shape)\n",
    "max_pra_len = tuple(torch.max(torch.tensor([paras.shape for paras in samples]), axis=0)[0])\n",
    "num_paras, para_length = s2.shape\n",
    "padded = torch.zeros(max_pra_len)\n",
    "padded[:num_paras, :para_length] = s2\n",
    "print(padded, padded.shape)\n",
    "pad_sequence([sample[key] for sample in input_samples], padding_value=self.PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = processor.to_dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(sample_batched[\"multi_paras\"].shape)\n",
    "#     print(BPE_processor.decode_tensor(sample_batched[\"tgt\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = BertConfig()\n",
    "model = BertModel(configuration).from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"raise an exception\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 29379,  3347,   102])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tokenizer.encode(\"foo bar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-571-737c8eb66a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1547\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1548\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, binary_chunk_size)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/file'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('path/to/file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pretrained(embeddings, freeze=True):\n",
    "    assert embeddings.dim() == 2, \\\n",
    "         'Embeddings parameter is expected to be 2-dimensional'\n",
    "    rows, cols = embeddings.shape\n",
    "    embedding = torch.nn.Embedding(num_embeddings=rows, embedding_dim=cols)\n",
    "    embedding.weight = torch.nn.Parameter(embeddings)\n",
    "    embedding.weight.requires_grad = not freeze\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoMarkModel(Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.multihead_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = Linear(d_model, dim_feedforward)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.linear2 = Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "        self.dropout3 = Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        r\"\"\"Pass the inputs (and mask) through the decoder layer.\n",
    "\n",
    "        Args:\n",
    "            tgt: the sequence to the decoder layer (required).\n",
    "            memory: the sequnce from the last layer of the encoder (required).\n",
    "            tgt_mask: the mask for the tgt sequence (optional).\n",
    "            memory_mask: the mask for the memory sequence (optional).\n",
    "            tgt_key_padding_mask: the mask for the tgt keys per batch (optional).\n",
    "            memory_key_padding_mask: the mask for the memory keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
    "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        tgt2, atts = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n",
    "                                   key_padding_mask=memory_key_padding_mask)\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        if hasattr(self, \"activation\"):\n",
    "            tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        else:  # for backward compatibility\n",
    "            tgt2 = self.linear2(self.dropout(F.relu(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt, atts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5., 2.], requires_grad=True)\n",
    "y = torch.tensor([-1., 1.], requires_grad=True)\n",
    "loss = (-(x**2)*y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., -4.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TranX: a semantic parser in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"src/external_repos/tranX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import astor\n",
    "import six.moves.cPickle as pickle\n",
    "from six.moves import input\n",
    "from six.moves import xrange as range\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import evaluation\n",
    "from asdl.asdl import ASDLGrammar\n",
    "from asdl.transition_system import TransitionSystem\n",
    "from common.utils import update_args, init_arg_parser\n",
    "from components.dataset import Dataset\n",
    "from components.reranker import *\n",
    "from components.standalone_parser import StandaloneParser\n",
    "from model import nn_utils\n",
    "from model.paraphrase import ParaphraseIdentificationModel\n",
    "from model.parser import Parser\n",
    "from model.reconstruction_model import Reconstructor\n",
    "from model.utils import GloveHelper\n",
    "from exp import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_parser = init_arg_parser()\n",
    "args = init_arg_parser().parse_args(\"--mode test \\\n",
    "                                     --load_model src/external_repos/tranX/data/pretrained_models/django.bin \\\n",
    "                                     --beam_size 15 \\\n",
    "                                     --test_file src/external_repos/tranX/data/django/test.bin \\\n",
    "                                     --save_decode_to 0.test.decode \\\n",
    "                                     --decode_max_time_step 100 \\\n",
    "                                     --example_preprocessor django_example_processor\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parser(\n",
       "  (src_embed): Embedding(718, 128)\n",
       "  (production_embed): Embedding(83, 128)\n",
       "  (primitive_embed): Embedding(541, 128)\n",
       "  (field_embed): Embedding(65, 64)\n",
       "  (type_embed): Embedding(17, 64)\n",
       "  (encoder_lstm): LSTM(128, 128, bidirectional=True)\n",
       "  (decoder_lstm): LSTMCell(704, 256)\n",
       "  (src_pointer_net): PointerNet(\n",
       "    (src_encoding_linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "  )\n",
       "  (primitive_predictor): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (decoder_cell_init): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (att_src_linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "  (att_vec_linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "  (query_vec_to_action_embed): Linear(in_features=256, out_features=128, bias=False)\n",
       "  (query_vec_to_primitive_embed): Linear(in_features=256, out_features=128, bias=False)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_cls = Registrable.by_name(args.parser)\n",
    "parser = parser_cls.load(model_path=args.load_model, cuda=args.cuda)\n",
    "parser.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start interactive mode\n",
      "load parser from [src/external_repos/tranX/data/pretrained_models/conala.bin]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4337607528d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractive_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/my_shared/notebooks/src/external_repos/tranX/exp.py\u001b[0m in \u001b[0;36minteractive_mode\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mutterance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Query:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mhypotheses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "interactive_mode(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load parser from [src/external_repos/tranX/data/pretrained_models/django.bin]\n"
     ]
    }
   ],
   "source": [
    "parser = StandaloneParser(args.parser,\n",
    "                              args.load_model,\n",
    "                              args.example_preprocessor,\n",
    "                              beam_size=args.beam_size,\n",
    "                              cuda=args.cuda)\n",
    "\n",
    "def predict(desc):\n",
    "\n",
    "    utterance = desc.strip()\n",
    "    hypotheses = parser.parse(utterance, debug=True)\n",
    "\n",
    "    pred_code_list = [hyp.code for hyp in hypotheses]\n",
    "    return pred_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "code_list = predict('foo is an empty array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo = []',\n",
       " \"foo = ''\",\n",
       " \"foo = ('', '', '', '', '')\",\n",
       " \"foo = ('', '', '')\",\n",
       " \"foo = ('', '', [])\",\n",
       " \"foo = ('')\",\n",
       " \"foo = '' + foo\",\n",
       " \"signals = ''\",\n",
       " 'signals = []',\n",
       " 'result = []',\n",
       " \"result = ''\",\n",
       " 'foo = {}',\n",
       " 'output = []',\n",
       " 'help_text = []',\n",
       " 'pass']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tree_sitter_AST_utils import Tree_Sitter_ENFA, sub_str_from_coords, Node_Processor, \\\n",
    "                                        Code_Parser, StringTSNode, get_grammar_vocab, regex_to_member, \\\n",
    "                                        NodeBuilder, PartialNode, sub_str_from_coords, PartialTree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src/external_repos/tree-sitter-python/src/grammar.json\", \"r\") as grammar_file:\n",
    "            python_grammar = json.load(grammar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_parser = Code_Parser(python_grammar, \"python\", parser_library_path='src/external_repos/tree-sitter-python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree generation terminated\n"
     ]
    }
   ],
   "source": [
    "seq = ['module', 'import_from_statement', 'from', '<REDUCE>', 'dotted_name', 'identifier', 'threading', '<REDUCE>', '<REDUCE>', 'import', \n",
    "       '<REDUCE>', 'dotted_name', 'identifier', 'local', '<REDUCE>', '<REDUCE>', '<REDUCE>', '<REDUCE>']\n",
    "tree = python_parser.sequence_to_partial_tree(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from threading import local \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RAY for parallel coomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 11:23:42,298\tERROR worker.py:655 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adder_Transform(object):\n",
    "    def __init__(self):\n",
    "        self.amount = [1,2]\n",
    "    \n",
    "    def __call__(self, samples):\n",
    "        self_ref = ray.put(self)\n",
    "        return ray.get([adder_Transform.process_sample.remote(self_ref, sample_obj) for sample_obj in samples])\n",
    "            \n",
    "    @ray.remote(num_cpus=0.5)\n",
    "    def process_sample(self, sample):\n",
    "        print(f\"computing {sample} amount_ref {self}\")\n",
    "        time.sleep(1)\n",
    "        sample[\"val\"] = self.amount\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f14b4465a90>\n",
      "\u001b[2m\u001b[36m(pid=159)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f2ebcaf1780>\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f3374167b70>\n",
      "\u001b[2m\u001b[36m(pid=160)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f5bbc63a470>\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f3f1c70d6d8>\n",
      "\u001b[2m\u001b[36m(pid=354)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f772c136710>\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f5ac24dde80>\n",
      "\u001b[2m\u001b[36m(pid=164)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f3a380e99b0>\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fb76803e390>\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f78901f0518>\n",
      "\u001b[2m\u001b[36m(pid=381)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f13fc254278>\n",
      "\u001b[2m\u001b[36m(pid=388)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7efd1439f208>\n",
      "\u001b[2m\u001b[36m(pid=164)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f3a380e9128>\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f14b4449438>\n",
      "\u001b[2m\u001b[36m(pid=159)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f2ebcaf12e8>\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7fb76803e898>\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f33741677b8>\n",
      "\u001b[2m\u001b[36m(pid=160)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f5bbc63a0f0>\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f78901f0b38>\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f3f1c706e48>\n",
      "\u001b[2m\u001b[36m(pid=354)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f772c136ba8>\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f5ac24dd8d0>\n",
      "\u001b[2m\u001b[36m(pid=401)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f7538271278>\n",
      "\u001b[2m\u001b[36m(pid=381)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f13fc254588>\n",
      "\u001b[2m\u001b[36m(pid=409)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7fe8a07c0278>\n",
      "\u001b[2m\u001b[36m(pid=408)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fd080533278>\n",
      "\u001b[2m\u001b[36m(pid=418)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f9a58743208>\n",
      "\u001b[2m\u001b[36m(pid=388)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7efd1439f518>\n",
      "\u001b[2m\u001b[36m(pid=159)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f2ebcaf1be0>\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f3374167be0>\n",
      "\u001b[2m\u001b[36m(pid=439)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f72e4209278>\n",
      "\u001b[2m\u001b[36m(pid=430)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f1a3c782278>\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f14b44496d8>\n",
      "\u001b[2m\u001b[36m(pid=164)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f3a380e9828>\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fb768088160>\n",
      "\u001b[2m\u001b[36m(pid=160)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f5bbc63a278>\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f789023a160>\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f3f1c706ef0>\n",
      "\u001b[2m\u001b[36m(pid=354)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f772c136c88>\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f5ac24dd7f0>\n",
      "\u001b[2m\u001b[36m(pid=447)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7fc00c383278>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 12:12:54,045\tWARNING worker.py:1047 -- WARNING: 30 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=401)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f7538271588>\n",
      "\u001b[2m\u001b[36m(pid=381)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f13fc2547b8>\n",
      "\u001b[2m\u001b[36m(pid=409)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7fe8a07c0588>\n",
      "\u001b[2m\u001b[36m(pid=408)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fd080533588>\n",
      "\u001b[2m\u001b[36m(pid=459)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f038458b2b0>\n",
      "\u001b[2m\u001b[36m(pid=418)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f9a58743518>\n",
      "\u001b[2m\u001b[36m(pid=388)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7efd1439f748>\n",
      "\u001b[2m\u001b[36m(pid=159)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f2ebcaf1f98>\n",
      "\u001b[2m\u001b[36m(pid=439)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f72e4209588>\n",
      "\u001b[2m\u001b[36m(pid=430)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f1a3c782588>\n",
      "\u001b[2m\u001b[36m(pid=504)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fdd3c1c6278>\n",
      "\u001b[2m\u001b[36m(pid=501)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f02dc0a5208>\n",
      "\u001b[2m\u001b[36m(pid=164)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f3a380e96d8>\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fb768088f28>\n",
      "\u001b[2m\u001b[36m(pid=160)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f5bc00fec88>\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f789023acf8>\n",
      "\u001b[2m\u001b[36m(pid=354)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f772c15ab00>\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7f5ac027db70>\n",
      "\u001b[2m\u001b[36m(pid=502)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f4780162278>\n",
      "\u001b[2m\u001b[36m(pid=447)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7fc00c383588>\n",
      "\u001b[2m\u001b[36m(pid=401)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f75382717b8>\n",
      "\u001b[2m\u001b[36m(pid=381)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f13fc2549e8>\n",
      "\u001b[2m\u001b[36m(pid=409)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7fe8a07c07b8>\n",
      "\u001b[2m\u001b[36m(pid=408)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7fd0805337b8>\n",
      "\u001b[2m\u001b[36m(pid=459)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f038458b588>\n",
      "\u001b[2m\u001b[36m(pid=418)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f9a58743748>\n",
      "\u001b[2m\u001b[36m(pid=388)\u001b[0m computing {'val': 5} amount_ref <__main__.adder_Transform object at 0x7efd1439f978>\n",
      "\u001b[2m\u001b[36m(pid=439)\u001b[0m computing {'val': 3} amount_ref <__main__.adder_Transform object at 0x7f72e42097b8>\n",
      "\u001b[2m\u001b[36m(pid=430)\u001b[0m computing {'val': 7} amount_ref <__main__.adder_Transform object at 0x7f1a3c7827b8>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-f687878e4838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madder_Transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-68b57c63ecbd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madder_Transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_ids, timeout)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mlast_task_error_raise_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_ids, timeout)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         data_metadata_pairs = self.core_worker.get_objects(\n\u001b[0;32m--> 305\u001b[0;31m             object_ids, self.current_task_id, timeout_ms)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_metadata_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = [{'val':3},{'val':7},{'val':3},{'val':7},{'val':5},{'val':7},{'val':3}]*10\n",
    "transform = adder_Transform()\n",
    "transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 0.001 s\n",
       "\n",
       "Total time: 0.216318 s\n",
       "File: <ipython-input-28-3efa78b1f144>\n",
       "Function: __call__ at line 5\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     5                                               def __call__(self, samples):\n",
       "     6         1        216.3    216.3    100.0          return ray.get([self.process_sample.remote(self, sample_obj) for sample_obj in samples])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 1e-3 -f adder_Transform.__call__ transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_ref = ray.put(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectID(ffffffffffffffffffffffff0100008011000000)\n"
     ]
    }
   ],
   "source": [
    "print(obj_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
